# はじめに
データ分析について学んでいれば、**ベイズ統計モデリング**という言葉を聞いた事のある方は多いかと思います。

一方でその知名度や有用性の高さに反して、**実際に活用されている方は意外に少ない**のでは、と考えております。
根拠として、ベイズ統計モデリングに使用される確率的プログラミング言語の**GitHub Star数推移**を下記します。
![スクリーンショット 2022-01-01 15.36.08 2.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/58286523-8fe5-b25e-edeb-3bee41696a0e.png)
データ分析で多用される深層学習や機械学習の有名ライブラリと比べ1桁少ないStar数となっており、Star数だけで一概に判断できないにせよ、実務への普及率は相対的に低いことが想定されます。

普及率が低めな理由として、「新規学習者向け教材で後回しにされがち」「Pythonでの実装に関する情報が少ない」等が考えられますが、いずれも「**勉強したいとは思っているが情報が少ないので後回し**」という性質のものが多いと感じました。

そこで本記事では、情報不足の解消に少しでも役立てるよう、**初心者が概要を理解して次に勉強すべき情報に辿り着く**ための記事を目指したいと思います。

今回私も学習してみて、ベイズ統計モデリングは[**深層学習や機械学習に勝るとも劣らない汎用性の広さ**]()があると感じたので、本記事が少しでも理解の助けとなり、活用できる人が増えればと思います。

# ベイズ統計モデリングとは？
[こちらの書籍](https://www.kspub.co.jp/book/detail/5165362.html)の定義をお借りするのであれば、

「確率的な表現を用いたモデル」を
「ベイズ統計学に基づき」計算し、
「予測や解釈に用いる」
ことを、ベイズ統計モデリングと呼びます。

上記を**必要となる知識に分解**すると、以下のようになります。

**A. 確率的な表現をモデル化 → 確率分布**
**B. ベイズ統計学 → 事前確率と事後確率**
**C. 予測に用いる → 回帰**
**D. 解釈に用いる → 区間推定等による判定**

これだけだと具体的なイメージが湧きずらいかと思うので概念図を下記しますが、今は**「上記A〜Dのパーツから構成される」**くらいの認識で良いかと思います。

**・ベイズ統計モデリングのイメージ図**
![図1.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/decda563-da89-ef54-47e5-07d0cb81639f.png)
上図を見て「**色々とメリットがありそう！**」と感じた方も多いかと思いますが、実際に多くのメリットを持つ汎用性の広い手法です（[詳しくは後述します]()）

<br>

上記の**モデルを構築**するためには、**以下の手順**（こちらも[書籍](https://www.kspub.co.jp/book/detail/5165362.html)の受け売りです）を実施します

**1. 現象の知識に基づき確率モデル（主に「A.確率分布」と「C.回帰」の組み合わせ）を構築する**
**2. 取得したデータとベイズの定理に基づき、モデルのパラメータの事後確率分布（事後分布）を計算する**
**3. データに対するモデルの当てはまりを評価する**

具体的な手順は、[実装]()パートで解説します。

## 機械学習と何が違うの？
ベイズ統計モデリングは機械学習とセットで語られることが多く、用途も被る部分が多いため、その違いと共通点を考えることで、理解の深化を目指します。

### 「統計」と「機械学習」の違い
データ分析の世界ではよく「統計」と「機械学習の違い」が議論に上がります。
検索上位の記事としては[こちら](https://exploratory.io/note/kanaugust/Gxe3giQ0zp)（[元記事](https://www.svds.com/machine-learning-vs-statistics/)）や[こちら](https://tjo.hatenablog.com/entry/2015/09/17/190000)が挙げられますが、いずれも端的に述べると

**統計**: 現象の「**解釈・推論**」に主眼を置き、分析過程を人間が理解できるよう分析・モデル構築する
**機械学習**: 結果の「**予測**」に主眼を置き、分析過程の理解を犠牲にしてでも予測性能の向上を目指す

と要約できそうです。

### ベイズ統計モデリングと機械学習の相違点
**ベイズ統計モデリング**は基礎となっている理論（ベイズの定理、確率分布等）や評価指標（AIC等のモデルの適合度を評価する指標）は統計に位置付けられるものが多く、何より手順の一部である「**現象の知識に基づきモデルを構築する（ホワイトボックス的なアプローチ）**」が、前述の統計の定義に合致していると考えられます。

これに対してSVMやLightGBM等の**機械学習アルゴリズム**は「**起こっている現象の解釈は問わず**（ブラックボックス的なアプローチ）、とにかく**予測精度を上げたい**」という側面が強いと言え、評価指標（MAE、Accuracy等）も予測精度に主眼を置いたものが使用されます。

その他にも実用上は「ベイズ統計モデリングは予測区間（ばらつき）の推定ができる」等の違い（メリット）も存在しますが、これらは[機械学習と比べたメリット]()で触れます。

### ベイズ統計モデリングと機械学習の共通点
一方で、[前述のように]()**「予測」もベイズ統計モデリングの目的**の一つに挙げられており、**用途の観点では機械学習と共通する面が多い**と言えます。

また、後述の[機械学習の正則化とベイズ推定の事前分布が同様の効果をもたらす例]()など、性能向上のためのテクニックにおいても本質的に共通する部分が多く存在します。

これらの相違点と共通点をまとめると、
**「基礎理論やモデル構築のアプローチは統計的だが、用途や性能向上テクニックは機械学習と共通する部分が多い」**
と解釈できるかと思います。

恐らく本記事を読まれている方も機械学習経験者が多いかと思うので、以後も機械学習との共通点に随時触れながら、紹介を進めていきます。

## 機械学習の知識をベースとした統計モデリングの解説
ベイズ統計モデリングは、「統計モデリング」のパラメータ推定に「ベイズ推定」を用いたモデル構築手法となります。
ですので、まずは「**統計モデリング**」について解説をすすめます

厳密に正確な表現ではありませんが、統計モデリングを機械学習と対比して理解しようとすると、下図の「**回帰**」と「**教師なし学習（確率分布の当てはめ）**」の**組み合わせ**とみなすと理解しやすいかと思います。
![図3.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/600bf832-b053-1e47-9e0e-5a7bccfd6607.png)

詳しく解説を進めます。

### ・回帰・教師なし学習と統計モデリングの関係
統計モデリングが「回帰と教師なし学習の組み合わせ」とみなしうる理由を解説します。
#### 教師なし学習
「教師なし学習」と一概に言っても様々な手法がありますが、混合ガウスモデル（GMM）やマハラノビス・タグチ法（MT法）のように**確率分布をあてはめる**手法は、最もポピュラーなモデル構築法の一つです。(下図は、データに2次元正規分布をあてはめる例です)
![図7.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/e2e8064f-9a07-08ad-bc13-f464ea149aee.png)

#### 回帰
回帰は「説明変数から目的変数の予測値を求める」事が目的の手法ですが、出力として**予測値の線**（説明変数が多次元なら超平面）が得られます。
![図4.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/be20d638-bc22-826e-ffb2-6be58b1e0148.png)

なお、機械学習で予測の対象となる変数は「目的変数」と呼ばれますが、ベイズ統計モデリングにおいては「**応答変数**」と呼ばれる事が多いので、以後「応答変数」に統一します。

#### 統計モデリング
統計モデリングの成果物となる「**確率的な表現を用いたモデル**」（[前述]()）ですが、具体的に得られる出力は「**説明変数によって変化する予測値の確率分布**」となります。

以下の図を見ていただければわかりやすいですが、これは**回帰の予測線を確率分布に置き換えたもの**とみなすことができ、まさに「教師なし学習（確率分布のあてはめ）」と「回帰（説明変数から求められる予測値の線）」の組み合わせとなっていることが分かります。
![図2.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/df9377fb-8f15-9f32-1a65-a1841954feb8.png)
※必ずしも平均値が回帰に従うとは限らず、確率分布の種類によっては他のパラメータが従います。

### ・統計モデリングとパラメータ推定
上記のような「確率分布」と「説明変数から求められる予測線」のパーツからなるモデルを構成するためには、

**・確率分布を求めるためのパラメータ**（例: 正規分布の平均・標準偏差）
**・説明変数から予測線**（確率分布の平均etc.となる）**を求めるためのパラメータ**（例: 一次関数の係数）

のような**パラメータを、データに対する当てはまりが良くなるよう求める必要**があります。

例えば、

- 確率分布: $平均\mu, 標準偏差\sigmaの正規分布$
- 説明変数: $1変数x$
- 説明変数と応答変数の関係: $応答変数yの平均\muが、説明変数xと傾きa, 切片bの線形関係$

というシンプルなモデルを定義します。
![図5.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/47b07bad-bb1d-eb71-b2a1-41278d87a650.png)

上記で**当てはめた確率分布の区間推定**（例えば下位2.5%～上位2.5%点の範囲 = データの95%が入る区間）を「**予測区間**」と呼び、今後頻出するので覚えていただければと思います。

応答変数yの確率分布をp(y)とすると、モデルの数式は以下のように表現できます

```math:
\mu=ax+b\\
p(y)=\frac{1}{\sqrt{2\pi\sigma^2}}\exp\Bigl(-\frac{1}{2\sigma^2}(y-\mu)^2\Bigr)
```
1行目の式が予測線（回帰的要素）を、2行目の式が正規分布（確率分布要素）を表しています。

見ての通り確率分布の式は複雑なので、**実用上**は以下の**簡略化したモデル式**を使用することが多いです
（[後述]()の確率的プログラミング言語Stanでの記法。[こちらの書籍](https://www.kyoritsu-pub.co.jp/bookdetail/9784320112421)参照）

```math:
\mu[n]=ax[n]+b\\
Y[n] \sim Normal(\mu[n],\sigma)
```
※Normal(μ,σ)は平均μ,標準偏差σの正規分布、添字nはデータ数分の要素を持ったベクトル、記号~は左辺のデータが右辺の確率分布から生成することを表しています

上記の例では
$\sigma, a, b$
の**3つのパラメータ推定**が必要となります。
**データに対する当てはまりのよいパラメータを推定する方法**には、大きく以下の2つの方法が存在します。

**[・最尤推定]()**
**[・ベイズ推定]()**

ベイズ統計モデリングにおいては、名前の通り後者のベイズ推定を使用します。
両者の[理論については後述]()するので、まずは**最尤推定と比べたベイズ推定のメリット**について解説します。

## ベイズ統計モデリングと最尤推定
[詳しくは後述]()しますが、最尤推定ではパラメータ（上例の$\sigma, a, b$）を固定値として求めるのに対し、ベイズ統計モデリングではパラメータ自体も確率分布として算出します。

この**パラメータの確率分布の区間推定を「信用区間」**と呼び、前述の**データ自体に当てはめた確率分布の区間推定**である「**予測区間**」と区別する必要があります。

実際に前記の例において最尤推定（[コードは後述]()）とベイズ推定（[コードは後述]()）で求めた信用区間、予測区間（当てはめた確率分布における下位2.5%～上位2.5%点の範囲）を、下にプロットします。

```r:最尤推定
```

```r:ベイズ推定
```
[最尤推定ではパラメータは説明変数xによらず固定値]()
[最尤推定では予測区間が一定]()

[ベイズ推定ではパラメータが説明変数xにより変化＆予測区間あり]()
[ベイズ推定ではデータが少ない部分の予測区間が広くなっている図]()

最尤推定はパラメータを固定値で求めるため信用区間が存在しないのは前述の通りですが、それ以外に目につく差として、**最尤推定では**説明変数によらず**予測区間が一定**（$\sigma$が一定）となっているのに対し、**ベイズ推定**では**データが多い部分では予測区間が狭く、データが少ない部分では予測区間が広く**なっています。

[両者の差を比較した図]()

### ・最尤推定と過学習
最尤推定では、データが多い部分でも少ない部分でもパラメータ$\sigma$を固定値として求めているため、**後者では少ないデータ（=推定の信頼性が低い）にパラメータが過剰に適合した「過学習状態」**となっていると言えます。

[信用区間一定を表す図]()
[最尤推定では予測区間が一定の図]()

上記の説明だけでは定性的ですが、**データが少ないときに最尤推定が過学習する理由は[後の章で数式でも解説します]()**

### ・ベイズ統計モデリングによる過学習防止
一方でベイズ統計モデリングでは、データが少ない部分では（事前分布に広い分布をとっていれば）パラメータの信用区間が広くなるため、**「データが少ない部分では信頼性が低いので、パラメータの推定値は曖昧（=広い信用区間）にしておく」**を表現することができ、過学習を防げていると言えます。

[ベイズ推定ではデータが少ない部分の信用区間が広くなっている図]()
[ベイズ推定ではデータが少ない部分の予測区間が広くなっている図]()

上記のように過学習を防げるというベイズ統計モデリングのメリットは、[機械学習における正則化](https://qiita.com/c60evaporator/items/784f0640004be4eefc51)と似ていますが、[後述のように]()事前分布が機械学習における正則化項の役割を果たしており、**ベイズ統計モデリングと機械学習の理論は密接に関係している**ことがわかります。

## ベイズ統計モデリングの特徴まとめ
ここまで述べたベイズ統計モデリングの特徴についてまとめると、以下のようになります

**・「確率分布（クラスタリング的要素）」と「説明変数から求められる予測線（回帰的要素）」のパーツからモデルを構築**
**・モデルのパラメータ推定にはベイズ推定を使用**
**・ベイズ推定により、最尤推定と比べ過学習しづらいというメリット**

# 実用上におけるベイズ統計モデリング
ベイズ統計モデリングがどのような場面で役立つかを、機械学習との比較を交えて考えていきます。

## 用途
ベイズ統計モデリングは、主に以下の用途に用いられます（分析対象はテーブルデータが主体）

**1. 予測**
**2. 異常検知**
**3. 時系列分析**
※上記全てにおいて、分析過程で様々な**「解釈」**も得られます

以下のように用途の多くは機械学習（および深層学習）重複しているため、**機械学習と比べたメリット＆デメリット**を考えていきます。

**・用途と使用されるアルゴリズム**

|用途|ベイズ統計モデリング|(ディープでない)機械学習|深層学習|
|---|---|---|---|
|1.予測|一般化線形モデル, 一般化線形混合モデル等|各種回帰モデル|Tabnet|
|2.異常検知|一般化線形モデル, 一般化線形混合モデル等|kNN, MT法等|Autoencoder等|
|3.時系列分析|状態空間モデル|AR、ARIMAモデル等|RNN|

機械学習と一概にどちらが優れているとは言えないので、後述する**メリット＆デメリットを鑑みて目的に合わせ使い分け**てください

## 機械学習と比べたメリット
機械学習と比べた際のメリットとして、主に以下が挙げられます

1. 明示的にモデル式を構築できるので、**説明性が高い**
2. **ばらつき**を表現できる（ベイズ予測区間）
3. 確率的に起こる現象のモデル化に強い
4. 区間推定による**解釈性の高さ**(ベイズ信用区間、変数変換)
5. 過学習を防ぎやすい

### 1. 説明性が高い
[詳しくは後述しますが]()、ベイズ統計モデリングでは**明示的なモデル式**を立式し、この式にデータをフィッテング(=パラメータ推定)させます

モデル式の立式には**ドメイン知識**（「重さは長さの3乗に比例する」のように、物理式や経験から想定される変数同士の関係）を反映させるため、ドメイン知識に精通した関係者や顧客への**説明性が高い**モデルと言えます。
データ分析において「**ステークホルダーに納得してもらうこと**」は関門の一つとなるため、**説明性の高さは大きなメリット**となります。

対して機械学習は明示的な式を立てずにブラックボックスで学習を行うため、「なぜこの結果となったか」の解釈が難しく、説明性が犠牲となりがちです。

また、事前分布にドメイン知識を適用することもできますが（これがメリットとして挙げられている例も散見されます）、[後述のように]()過学習の原因となりうるため、[こちらの書籍](https://www.kyoritsu-pub.co.jp/book/b10003786.html)ではむやみに狭い分布を指定することは避けるべきと述べられています。

### 2. ばらつきを表現できる
世の中で重要な役割を果たしているにも関わらず、分析において無視されがちな要素として、「**運**」が挙げられます。

仕事が成功するかも、テストで何点取れるかも、野球でヒットを打てるかも、**運の要素を無視して**確定値になることを想定して分析すると、**下振れした時のリスクに対処できず**に大ダメージを被る恐れがあります。
(実は「運」だと思っていた要素も突き詰めると原因があったりしますが、観測できていない時点で「運」の影響とみなした方が、実用上はモデル化しやすい事が多いです)

運によりどの程度下振れするか・上振れするかは、データ上の「ばらつき」として観測することができます。

[先ほど]()少し触れましたが、ベイズ統計モデリングでは確率分布をモデルに含めることで、予測値（点推定）だけでなく「**ベイズ予測区間**」という、**ばらつきを表現する指標**を求めることができ、機械学習では困難な**下振れや上振れを考慮した分析**を実現する事ができます。

また、実用上のデータ分析において「**ばらつきの範囲を超えて値が変化したら異常とみなす**」という「**異常検知**」の手法もよく用いられており、ベイズ統計モデリングは「**予測**」だけでなく、「**異常検知**」にも用いることができる**一度で二度美味しい手法**と言うことができます。

例えば工業用途でよくあるケースとして、品質指標を応答変数、型番やセンサの値を説明変数としてベイズ統計モデリングし、品質や不良率を「予測」しつつ、予測範囲を超えた品質悪化の発生を「異常検知」する、といった使われ方が挙げられます。

### 3. 確率的に起こる現象のモデル化に強い
機械学習は確率的に起こる現象、特に「○回中△回起こる確率」の◯が変化する場合（応答変数の分母が変化）や△が小さい場合（確率の低い現象）に弱いアルゴリズムが多くを占めます。

一方でベイズ統計モデリングは、[後述のように]()多様な確率分布やリンク関数をモデル内に内包する事ができるため、上記の機械学習が苦手とする分野に対しても対応が可能です。

後述の[二項ロジスティック回帰モデル]()や[ポアソン回帰モデル]()はその代表例として挙げられます。

### 4. 区間推定を直感的に理解しやすい
[前述のように]()、ベイズ統計モデリングににはパラメータの存在範囲を示す**「信用区間」**と、応答変数自体の存在範囲（前節のばらつき）を示す**「予測区間」**という、2種類の区間推定が存在します。

似たような概念として他の統計分野（推計統計学や線形回帰）において多用される**「信頼区間」**が存在しますが、例えば「95％信頼区間」とベイズ統計モデリングにおける「95％信用区間」「95％予測区間」の解釈を比較すると、以下のようになります。

|区間推定の名称|95%区間推定の解釈|
|---|---|
|信頼区間|「100回信頼区間の推定を行うと、95回真のパラメータが信頼区間内に含まれる」|
|信用区間|「パラメータが95％の確率で信用区間内に含まれる」|
|予測区間|「応答変数が95%の確率で予測区間内に含まれる」|

よく[信頼区間の誤用例](https://bellcurve.jp/statistics/course/8891.html)として信用区間の定義があげれることがありますが、それだけ**信頼区間は直感的に理解しづらい**概念と呼べ、**相対的に理解しやすい概念である信用区間・予測区間**の存在は、前述の**解釈性向上に寄与**すると言え、他者にモデルを説明するときも納得してもらいやすくなるでしょう。

上記を「誤用」とすること自体が間違いとの意見もあるので、本メリットは削除させて頂きます

https://twitter.com/genkuroki/status/1161863759431782400?t=yokDEanOrZLYylj1WDqTfg&s=19

### 5. 過学習を防ぎやすい
[前述のように]()ベイズ推定は、原理自体に過学習を防ぐ仕組みが組み込まれているため、**データが少ない場合でも過学習しづらい**という特徴があります。

ただしこのメリットには注意点があり、

・機械学習にも正則化等の過学習を防ぐ仕組みが組み込まれており、一概に「機械学習と比べて過学習防止効果に優れる」とは言い切れない
・事前分布に分散の狭い分布を指定すると、逆に過学習（バイアス）の原因となりうる（[前述]()）

の2点に注意する必要があります。

## 機械学習と比べたデメリット
機械学習と比べた際のデメリットとして、主に以下が挙げられます

1. 明示的に式を与える必要があるので、**ドメイン知識が必要**
2. 実装のための情報が少ない
3. Pythonでの実装難度が高い
4. 純粋な予測性能は機械学習の方が上げやすい

### 1. 明示的に式を与える必要があるので、ドメイン知識が必要
ベイズ統計モデリングはモデル式を明示的に与える必要があり、[後述のように]()**精度の高いモデル式を考える**ためには**統計の知識や分析対象に対する深いドメイン知識**が必要となるため、分析に多大な事前知識が必要と言えます。

これに対し**機械学習**では、モデル式を与えなくとも**「予測線がデータに合わせて自動でぐにゃっと曲がってフィッテイング」**してくれるため、**事前知識が乏しくとも簡単に予測できてしまう**というメリットがあります（一応ベイズ統計モデリングにも、「ガウス過程回帰」と言う「ぐにゃっと曲がってフィッティング」してくれる手法は存在しますが）

[ベイズ統計モデリングと機械学習のフィッティングの差を図示]()

以前は「ぐにゃっと曲がる」処理の調整に必要なハイパーパラメータチューニングに手間が掛かりましたが、[近年はパラメータチューニングの自動化技術も進歩](https://qiita.com/c60evaporator/items/ca7eb70e1508d2ba5359)しており、また機械学習の弱点である解釈性の低さに関しても、[木構造アルゴリズムのFeature importance](https://qiita.com/c60evaporator/items/c930c822b527f62796ee#特徴量重要度feature-importance)や[LIME, SHAP](https://technomado.jp/column/ai/8296/)等の「お気軽に実装できる解釈用アルゴリズム」が増えており、**「知識が乏しくとも簡単に予測できる手軽さ」**での機械学習の優位性はますます広がっていると言える状況です。

私見にはなりますが、この**手軽さが[冒頭で触れた機械学習の普及]()の原因の一つ**となっているように思えます。

とはいえ知識さえあればベイズ統計モデリングは[前述の多大なメリット]()を享受できる手法なので、**しっかり勉強して知識を身に付ければ、ベイズ統計モデリングは強力な分析用ツールとなりうる**と言えるでしょう。

### 2. 実装のための情報が少ない
[前述のStarの数]()からも分かる通り、機械学習と比べると実際に活用している人の数が少なく、ネット上や書籍による情報収集の選択肢も少ないと言えます。

この差の原因には[前述の機械学習の手軽さ]()もあるかと思いますが、**「機械学習がブームとなったこと」**や**「機械学習や深層学習にはScikit-LearnやTensorFlow, PyTorchというデファクトスタンダードなPythonライブラリが存在すること」**も寄与していると、個人的には考えています。
[後述しますが]()ベイズ統計モデリングは多くのライブラリが乱立しており、**実装に関する情報もライブラリごとに分散**しているため、どれを学習すべきか二の足を踏む現状となっています。

上記のように実装面に関しては情報不足の感は否めませんが、**理論面に関しては**ベイズ統計モデリングは機械学習に勝るとも劣らない数の**良質がある**ので、[参考書籍]()を参照頂ければと思います。

### 3. Pythonでの実装難度が高い
統計分野においては伝統的にRが用いられたという経緯から、**ベイズ統計モデリングにおいてもRを主流として開発が進んで**来ました。
近年はPyMCやTensorFlow Probability、Pyro等のPython向け確率的プログラミング言語も増えてきましたが、実装情報、特に書籍化されている情報に関しては現状でもR、およびその主な確率的プログラミング言語であるRStanが圧倒的に多く、Pythonを好むユーザにとっては大きなハードルとなっています。

また、情報が少ないだけでなく**環境構築でハマりやすいこともPythonの難点**です。
ライブラリの種類の多さ、パッケージ管理ツールの統一性のなさ（pipとconda）、IDE（VSCode等）の種類の多さなど、環境構築をする上でネックとなりやすい要素が多く、私もVSCodeのバージョンをアップしたらPyStanのコードが動かなくなって一日を無駄にしてしまった経験があります。
Rでの環境構築も決して簡単ではありませんが、Pythonと比べると方法が統一されている（IDEやパッケージ管理が実質1種類）こともあり、ハマにくさや情報の集めやすさに分があると言えます。

### 4. 純粋な予測性能は機械学習の方が上げやすい
[前述]()のように、**機械学習は**「分析過程の理解を犠牲にしてでも予測性能の向上を目指す」ことを目的としており、予測性能向上のためのアルゴリズムの工夫が随所に凝らされているため、**予測性能自体はベイズ統計モデリングよりも簡単に上げられることが多い**です。

多くのデータにおいて、ベイズ統計モデリングで高性能の機械学習モデル（LightGBM等）を超える予測性能を出すことは至難の業と言えるでしょう。

ただし、実用上は「カリカリにチューニングして性能向上しないとモデルが採用されない」ケース以上に、**ベイズ統計モデリングの長所である「解釈性の高さ」や「ばらつきを表現できる事」が採用の決め手**となるケースが多いとも感じるため、このあたりは用途に合わせて適切に選択するのが良いかと思います。

# ベイズ統計モデリングに必要な前提知識
[前述のように]()「ベイズ統計モデリング」は以下の理論を組み合わせて構成されています。

A. 確率分布 → 確率的な表現をモデル化
B. ベイズ統計学 → 事前確率と事後確率
C. 回帰 → 予測に用いる
D. 区間推定 → 解釈に用いる

これらについて、モデリングに最低限必要な知識を解説します。

それなりのボリュームにはなりますが。読了する頃には**簡単なモデルの実装には十分な知識が身に付く**かと思いますので、**ご一読頂ければ**と思います。

## A. 確率分布
**確率分布**とは、[JI Z 8101-1 : 1999](http://kikakurui.com/z8/Z8101-1-1999-01.html)によると

**「確率変数がある値となる確率，又はある集合に属する確率を与える関数」**

と定義されています。

例えば、変数xが下図のような確率分布p(x)に従う場合、変数xは3付近となる確率が最も高く、そこから離れる値ほど確率が低くなります。
<img width="480" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/694a7699-fd52-9078-52cd-4ea987d9aeba.png">
また、上記の変数xのように確率的に発生する変数を**確率変数**と呼びます。

[前述のように]()世の中の多くの現象はばらつきを持って確率的に変化するため、確率変数で表すことができ、このような現象の表現に統計モデリングが威力を発揮します。

### 1変数の確率分布
1変数において確率分布は、前述の変数xのグラフのように**単純な1変数関数**で表すことができます。
よく使う確率分布の種類については[後述します]()が、例えば最も使用頻度の高い**正規分布**は以下の式で表されます。

```math
p(x)=\frac{1}{\sqrt{2\pi\sigma^2}}\exp\Bigl(-\frac{1}{2\sigma^2}(x-\mu)^2\Bigr)
```
ここで重要な事実として、原理上は確率分布に従う変数であっても、現実世界では有限のデータ（サンプル)しか観測できないため、確率分布の形状を知るためには**限られたサンプルから推定**する必要があります。
<img width="480" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/3e51f973-b7c4-0dec-0b8a-1b089d0c5c9d.png">
この推定には最尤推定やベイズ推定を使用しますが、[詳細は後述します]()。

また確率分布は「確率を表現する」という特性上、全てのパターンの確率を足し合わせると1になる必要があります。
上記の条件は連続変数の確率分布では、下記のように**積分すると1になる**ことを表します。

```math
\int_{-\infty}^{\infty} p(x)dx=1
```

### 多変数の確率分布（同時確率と周辺確率）
確率変数が多変数の時、確率分布は多変数関数で表されます。
例えば確率変数x1, x2の2次元で構成される正規分布の関数は、以下のような山型の3Dグラフで表す事ができます。
<img width="400" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/19ebeccd-181b-a5c3-37a3-347f16ef692c.png">
上記3Dグラフは、「変数x1(横軸)と変数x2(縦軸)が同時にある値をとる確率が、関数の値(高さ)となる」と解釈できます。
このような**複数の変数が同時にある値をとる確率**を、**同時確率**と呼びます。多変数の確率分布は基本的にこの同時確率で表されます。

ベイズ統計モデリングにおける[**パラメータの事後分布**]()もこの**同時確率**で得られるため、本記事において重要な概念となります。

また、ある変数を積分することで消去し、より少ない変数で表せるようにした確率分布を**周辺確率**と呼びます。
<img width="720" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/60ab4a12-f66a-a0b6-1cc4-3b59b1b7c234.png">
周辺確率は[後述のベイズの定理の分母として登場]()し、また上図のように周辺化をすることで**シンプルな表現が可能**となるため、**可視化にも有用な手法**となります。
（[後述の事後分布の可視化]()でも、基本的には周辺化された確率分布をグラフとしてプロットします）

#### ・多変数における分散と共分散
注意すべきは、個々の確率変数の値は独立に決まるとは限らず、お互いに相互作用（「例：片方の確率変数の値が大きいときもう片方の値も大きくなる可能性が高い」）を持つことがある点です。

このような相互作用を表すために、多次元の確率分布では分散を**分散共分散行列**と呼ばれる行列で、確率変数をベクトルで表記することが一般的です。

下図のように分散共分散行列は
・対角成分 → 分散(相互作用を含まないばらつき)
・非対角成分 → 共分散(相互作用を含むばらつき)
を表しています

[図]()

以上をふまえて、2次元正規分布の同時確率は以下の式で表されます。

```math
```

3変数以上の解説は割愛しますが、基本的には上記と同様に行列で相互作用を表現します。

また多変数の確率分布も1次元と同様、積分すると1になる必要があります。

```math
\int p(\boldsymbol{x}) \boldsymbol{x}=1
```

### ベイズ統計モデリングにおける確率分布
[詳しくは後述します]()が、ベイズ統計モデリングでは以下の確率分布が登場します。

||確率分布の算出対象|確率分布の決め方|
|---|---|---|
|1|事前分布|無情報事前分布（ドメイン知識によっては弱情報を付加）|
|2|統計モデリングの確率分布(尤度関数)|**ドメイン知識**|
|3|パラメータの事後分布(信用区間の算出に使用)|MCMCにより多変数の確率分布（同時分布）として求まる|
|4|事後予測分布(予測区間の算出に使用)|パラメータ事後分布に基づき1変数の確率分布として求まる|

3, 4についてはベイズ推定により数値的に求まる（[前述]()および[後述]()の信用区間と予測区間の解説を参照ください）ため、モデリング前に決める必要があるのは「1.事前分布」と「2.当てはめる確率分布（尤度関数）」です。

#### 1.事前分布
ネット上ではよく「事前分布はドメイン知識によって決める」と書かれている例を見ますが、**事前分布の明示的な指定はドメイン知識、統計の知識ともに深い理解が求められる**ため、[こちらの書籍](https://www.kyoritsu-pub.co.jp/bookdetail/9784320112421)では**情報を持たない広い分布（無情報事前分布）の指定**が推奨されています。

理由として、むやみな事前分布の指定は[後述の例のように]()分析者の主観的なバイアス（≒過学習）を結果に反映させてしまうため、分析の再現性が下がることが挙げられます。

**無情報事前分布としては、十分に幅の広い一様分布や正規分布**がよく使用されます（[前述の書籍](https://www.kyoritsu-pub.co.jp/bookdetail/9784320112421)によると、Stanのデフォルトでは幅の広い一様分布が使用されるようです）

#### 2.統計モデリングの確率分布（尤度関数）
[前述のように]、ベイズ統計モデリングに限らず統計モデリングでは、事前に「当てはめる確率分布の種類」を指定する必要があります。[後述しますが]()ここで定めた確率分布のデータ数分の積が尤度関数となります。

指定できる分布の種類は非常に多いですが、以下の確率分布はよく使用するので、覚えた方がモデル検討のスピードが上がるかと思います。

##### ・正規分布 (Normal)
基本中の基本です。まずはこの分布に従うかどうか確認しましょう

平均, 標準偏差の2個のパラメータからなります
![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/6932a78b-9974-15bd-a7be-3d085e344452.png)
正規分布の確率密度関数は以下の式で表されます。

```math
p(x)=\frac{1}{\sqrt{2\pi\sigma^2}}\exp\Bigl(-\frac{1}{2\sigma^2}(x-\mu)^2\Bigr)
```

##### ・対数正規分布
正規分布に従う変数Xに対し、exp(X)が従う分布です。
左右非対称、かつ裾が重い特徴があり、年収等が従う分布と言われています。
正の変数で左右非対称の分布形状が見られるとき、ガンマ分布と共によく使用されます。

μ, σの2個のパラメータからなります
![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/4716b507-9363-22af-a942-691b08855a97.png)
対数正規分布の確率密度関数は以下の式で表されます。

```math
p(x)=
{\left\{\begin{array}{ll}
\frac{1}{x\sqrt{2\pi\sigma^2}}\exp\bigl(-\frac{1}{2\sigma^2}(\log x-\mu)^2\bigr) \quad (x\geq 0)\\
0 \quad (x<0)\\
\end{array}\right.}
```

##### ・スチューデントのt分布
裾が重い分布で、パラメータdf(自由度)=1のとき、コーシー分布と一致します。
外れ値が多いデータのモデル化によく利用されます。

自由度dfの1個のパラメータからなります
![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/097da11e-4607-d08d-67ce-ef4b6555a495.png)
t分布の確率密度関数は以下の式で表されます(νは自由度dfを表します)

```math
p(x)=\dfrac {\Gamma(\dfrac {\nu+1}{2})}{\sqrt{\nu\pi}\Gamma(\dfrac {\nu}{2})}\biggl( 1+\dfrac {t^2}{\nu}\biggr)^{-\frac {\nu+1}{2}}
```

##### ・一様分布
全ての値が一定確率で起こるときの分布です。宝くじやルーレットはこの分布に従います（従わなければイカサマ）

下限a、上限bの2個のパラメータからなります
![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/1bb9048d-44a8-735e-de95-9526deb136f9.png)
一様分布の確率密度関数は以下の式で表されます。

```math
p(x)=
{\left\{\begin{array}{ll}
\frac{1}{b-a} \quad (a\leq x\leq b)\\
0 \quad (x<a, b<x)\\
\end{array}\right.}
```

##### ・指数分布
一定確率で起こる現象が、1回起こるまでの時間が従う分布です。
故障や災害など、ある現象が次に起こるまでの時間をモデリングする際に使用されます。
![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/5174e412-2180-1efb-804b-ffec0f625aca.png)
指数分布の確率密度関数は以下の式で表されます。

```math
p(x)=\lambda\exp(-\lambda x)
```

なお、発生率が一定でなく時間変化する場合、[ワイブル分布](https://qiita.com/c60evaporator/items/fc531aff0cdbafac0f42#ワイブル分布)が使用できます。機械の故障率は初期不良や経年劣化で時間変化することが多いため、そのモデリングによく使用されます。
![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/1064fbe0-7ee7-04a9-6e57-a87534feef0c.png)
ワイブル分布の確率密度関数は以下の式で表されます。

```math
p(x)=
{\left\{\begin{array}{ll}
\frac{bx^{b-1}}{a^b}\exp\bigl(-(\frac{x}{a})^{b}\bigr) \quad (x\geq 0)\\
0 \quad (x<0)\\
\end{array}\right.}
```

##### ・ガンマ分布
一定確率で起こる現象が、n回起こるまでの時間が従う分布です。
主に待ち時間等の分析に利用されますが、時間だけでなく連続量の分析にも使われる汎用性の広い分布です。
連続量においては、左右非対称な特徴をもつ、人間の体重等が従う分布と言われています。

λ, kの2個のパラメータからなります(θ=1/λを使用することもあります)
![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/93aec1bc-3b18-ad80-e2ba-3fe294cafe5d.png)
ガンマ分布の確率密度関数は以下の式で表されます。

```math
p(x)=
{\left\{\begin{array}{ll}
\frac{\lambda^{k}}{\Gamma(k)}x^{k-1}\exp(-\lambda k) \quad (x\geq 0)\\
0 \quad (x<0)\\
\end{array}\right.}
```

##### ・ベルヌーイ分布
ここからは離散型の確率分布（確率質量関数）となります。

[後述のロジスティック関数]()と組み合わせて、確率的に起こる事象が「起こるか起こらないか」（ブーリアン型変数）を応答変数とするモデリングによく使用されます。
[図]()
ベルヌーイ分布の確率質量関数は以下の式で表されます。

```math
p(x)=
{\left\{\begin{array}{ll}
p \quad (x=1)\\
1-p \quad (x=0)\\
\end{array}\right.}
```

##### ・二項分布
[後述のロジスティック関数]()と組み合わせて、確率的に起こる事象が「N回試行した時に何回起こるか」を応答変数とするモデリングによく使用されます。
工業における生産数や野球の打数など、「N回」の数が大きく変動する事象で有用な手法と言えます。
[図]()
二項分布の確率質量関数は以下の式で表されます。

```math
p(x)={}_n C_x p^x (1-p)^{n-x}
```

試行回数が多い場合、二項分布は

・**発生率pが小さいとき**（n>20かつp<0.05,またはn>100かつnp<10[のとき](https://en.wikipedia.org/wiki/Binomial_distribution#Poisson_approximation)） → **ポアソン分布**
・**発生率pが0.5に近いとき**（np>5かつn(1-p)>5[のとき](http://www.utp.or.jp/book/b300857.html)） → **正規分布**

**で近似でき**、正規分布やポアソン分布の方が確率的プログラミング言語の計算速度が速いため、この条件を満たす場合はポアソン分布or正規分布が代用して使用される場合が多いです（例：生産数が常に1000以上の工業製品データ）


##### ・ポアソン分布
[前述のように]()、発生率が低い現象の二項分布を近似できる分布で、分母が連続量(時間, 面積etc.)の時も適用可能です。
[後述の指数関数]()と組み合わせて、確率的に起こる事象が「時間や面積あたり何回起こるか」を応答変数とするモデリングによく使用されます

[ポアソン分布の図]()
ポアソン分布の確率質量関数は以下の式で表されます。

```math
p(x)=\frac{\exp(-\lambda)\lambda^x}{x!}
```

## B. ベイズの定理
[前述のように]()、ベイズ統計モデリングではモデルのパラメータ推定にベイズの定理を用います。

[前述の**ベイズ統計モデリングのメリット**]()の多くは**ベイズの定理に由来**しているため、メリットを理解した活用のためにも本章を精読頂ければと思います。

### 使用するデータ例
ベイズの定理は、2種類以上の確率変数の間に成り立つ関係です。

本章では以下のように、[政府統計](https://www.data.jma.go.jp/obd/stats/etrn/index.php)から1月の雪日数(1991-2020年平均)を取得して集計したデータを使用します

|都市名|雪が降っている日数|雪が降っていない日数|
|---|---|---|
|札幌|29.1|1.9|
|仙台|20.6|10.4|
|東京|2.8|28.2|
|名古屋|5.4|25.6|
|大阪|4.7|26.3|
|福岡|6.3|24.7|
上記データでは、「都市名」と「雪が降っているか」が確率変数となります。
（「雪が降っていないか」は「雪が降っているか」に従属するため除外）

表記しやすいよう
**「都市名」をY**
**「雪が降っているか」をX**
として議論を進めていきます。

### 確率の加法定理と乗法定理
まずはベイズ理論の基礎となる**確率の加法定理**と**確率の乗法定理**について解説します。
#### ・同時確率
$X=x_i$かつ$Y=y_j$となる確率を**同時確率**と呼び、

```math
p(X=x_i, Y=y_j)
```
と表記します。

例えば
$p(X=雪,Y=大阪)$
は、「都市名が大阪かつ雪が降っている確率」を表しています。

なお、
$X=x_iかつY=y_j$となる確率
と
$Y=y_jかつX=x_i$となる確率
は等しいので、同時確率は以下の対称性が成り立ちます。

```math
p(X,Y)=p(Y,X)
```

#### ・周辺確率
Yが（Xと無関係に）ある値$y_j$をとる確率を

```math
p(Y=y_j)
```
と表記し、**周辺確率**と呼びます。

例えば
$p(Y=大阪)$
は、「都市名が大阪である確率」を表しており、雪が降っている場合と降っていない場合両方を含みます。

#### ・確率の加法定理
上記の例では、周辺確率$p(Y=大阪)$は、
「都市名=大阪」であるときの、「雪が降っているか」「雪が降っていない」両方のケースの和となります。
すなわち、
$p(Y=大阪)=p(X=雪,Y=大阪)+p(X=雪でない,Y=大阪)$
となります。

このように**周辺確率は、同時確率の、消去したい変数**(上例ではX)**の全てのパターンに対する和**となります。
これを一般化した式で表すと、

```math
p(Y=y_j)=\sum_{i} p(X=x_i,Y=y_j)
```
となり、**確率の加法定理**と呼びます。
これは簡略化して以下のように表記できます

```math
p(Y)=\sum_{X} p(X,Y)
```
変数を逆にしても同様の定理が成り立ちます。

```math
p(X)=\sum_{Y} p(X,Y)
```

この確率の加法定理は、[前述の確率分布における周辺化]()と原理的には同じで、
・消去する変数が**離散変数**のとき(例：上記の「雪が降っているか」) → **同時確率の和**が周辺確率となる
・消去する変数が**連続変数**のとき(例：[前述の確率分布における周辺化]()) → **同時確率の積分**が周辺確率となる
と解釈できます。

すなわち連続変数では確率の加法定理は以下のように表せます

```math
p(x)=\int p(x,y)dx
```

#### ・条件付き確率
$X=x_i$の条件下において$Y=y_i$となる確率を

```math
p(Y=y_j \mid X=x_i)
```
と表記し、**周辺確率**と呼びます。

#### ・確率の乗法定理
同時確率、すなわち「$X=x_iかつY=y_j$となる確率」は、

$X=X_i$となる確率(周辺確率)
と
$X=x_iの条件下でY=y_j$となる確率(条件付き確率)
の積となります。

これを**確率の乗法定理**と呼び、以下の式で表されます。

```math
p(X=x_i,Y=y_j)=p(Y=y_j \mid X=x_i) p(X=x_i)
```
これは簡略化して以下のように表記できます。

```math
p(X,Y)=p(Y \mid X) p(X)
```
また同時確率の対称性をYの周辺確率に対して適用すると、乗法定理にも対称性が成り立つことが分かります。

```math
p(X,Y)=p(Y,X)\\
=p(X \mid Y) p(Y)
```

例えば先ほどの例において乗法定理を適用すると、以下のような計算が可能です。
（※都市名が大阪である周辺確率$p(Y=大阪)=1/6$と仮定します）

```math
p(X=雪,Y=大阪)=p(X=雪 \mid Y=大阪)p(Y=大阪)\\
= 4.7/31 \cdot 1/6\\
= 0.0252 \cdots
```

### ベイズの定理
確率の乗法定理をXの周辺確率に対して適用すると、以下のようになります。

```math
p(X,Y)=p(Y \mid X) p(X)
```

同様に確率の乗法定理と同時確率の対称性をYの周辺確率に対して適用すると、以下のようになります。

```math
p(X,Y)=p(Y,X)\\
=p(X \mid Y) p(Y)
```
上記2式の左辺は等しいので、右辺同士を比較すると以下のようになります

```math
p(Y \mid X) p(X)=p(X \mid Y) p(Y)\\
```

```math
\Rightarrow p(Y \mid X)=\frac{p(X \mid Y) p(Y)}{p(X)}
```
この式を**ベイズの定理**と呼び、この定理に基づき推定したい確率等を得る方法を**ベイズ推定**と呼びます。

なお、ベイズの定理には4つの項が出てきますが、それぞれの項のベイズ推定における一般的な名称は、上記で解説した名称と異なるものが多いため、下記に一覧表記します

**・ベイズの定理における各項の名称**

|数式|上記解説における名称|ベイズ推定における名称|
|---|---|---|
|$p(Y｜X)$|条件付き確率 (Xを与えたときのYの確率)|事後確率（事後分布）|
|$p(X｜Y)$|条件付き確率 (Yを与えたときのXの確率)|尤度|
|$p(Y)$|周辺確率(Y)|事前確率（事前分布）|
|$p(X)$|周辺確率(X)|周辺尤度|
以降の解説では、「ベイズ推定における名称」を使用します。

### ベイズ推定の応用
ベイズ推定を活用できる典型的パターンは、
「**Yが直接観測できない時**に、与えられた**Xの情報(データ)**と、ドメイン知識等から設定した**事前分布**から、**Yの確率を推定**する」
というものです。

上記だけでは分かり辛いかと思うので、具体例を考えます

#### ・問題設定
例題として以下のような問題を考えます。

- 目隠しされて[前記6都市]()のいずれかに連れていかれる(どの都市かは分からない)
- 目隠しを外した後雪が降っているかどうかで、連れていた都市がどこかを推定する
- 都市名を当てたとき、以下の表に基づき賞金が貰える

|都市名|当てたときの賞金額|
|---|---|
|札幌|1000円|
|仙台|2000円|
|東京|10000円|
|名古屋|5000円|
|大阪|6000円|
|福岡|4000円|

上記のケースでは目隠しされているため、都市名**Yは分かりません**
そこで「雪が降っているか」という**間接的な情報X**から、**ベイズの定理によりYが各値をとる確率を求めます**

これは「Xを与えたときのYの確率」、すなわち事後分布$p(Y｜X)$の定義と合致するため、ベイズの定理で推定が可能です。

#### ・上記問題の解法
ベイズの定理で事後分布を求めるためには、分子の**「尤度」と「事前確率」**を明確化する必要があります。
（分母の「周辺尤度」は分子が求まれば積分が1となるよう[規格化して消去可能]()）

尤度$p(X｜Y)$は「Yを与えたときのXの確率」、すなわち「各都市ごとに雪が降る確率」を表しています。
これは[前述の1月の降雪日数のデータ]()が使用できるため、

```math
尤度p(X \mid Y)=\frac{1月の降雪日数}{1月の全日数31日}
```
とします

<br>

事前確率$p(Y)$は、「Xが与えられる前のYの確率」を表します。
本ケースでは都市名の推定に使用できる情報はX（雪の有無）以外にありません
このように**事前情報が全くない**場合は、**事前確率に等確率を設定**（全て1/6）することが多いです。

以上により尤度と事前確率
掛け合わせることでベイズの定理の分子（下表の「事前確率×尤度」）が求まります。

**都市名Xごとのベイズ推定結果**

|都市名|事前確率|尤度|事前確率×尤度|事後確率|
|---|---|---|---|---|
|札幌|1/6|29.1/31 = 0.939|0.156|0.156/0.37 = **42.2%**|
|仙台|1/6|20.6/31 = 0.665|0.111|0.111/0.37 = **29.9%**|
|東京|1/6|2.8/31 = 0.090|0.015|0.015/0.37 = **4.1%**|
|名古屋|1/6|5.4/31 = 0.174|0.029|0.029/0.37 = **7.8%**|
|大阪|1/6|4.7/31 = 0.152|0.025|0.025/0.37 = **6.8%**|
|福岡|1/6|6.3/31 = 0.203|0.034|0.034/0.37 = **9.1%**|
|計|1|-|**0.37**|100%|

求まった**「事前確率×尤度」は事後確率に比例**しますが、合計が1とならないためそのまま確率として使用することはできません。

**事後確率**を求めるためには、**「事前確率×尤度」を合計が1となるよう規格化**（「事前確率×尤度」の合計=0.37で割る）する必要があります。
これにより求まった事後確率を、都市名ごとに上の表に記載しています。

また、変数X以外に新たな情報（例：気温を表す変数Z）が手に入った場合、上表の事後確率を新たな事前確率とし、手に入った情報に基づく尤度を設定（例：都市ごとの平均気温）することで、さらなるベイズ推定を実施して推定の精度を上げることもできます。

このように**事後確率の更新**が行えることも、ベイズ推定のメリットの一つと言えます。

#### ※おまけ：賞金の期待値
ベイズ推定自体は上記事後確率を求めた時点で完了ですが、どの都市を指名したら賞金の期待値が高くなるかも求めてみましょう。

|都市名|当てたときの賞金額|事後確率|賞金の期待値 (賞金額×事後確率)|
|---|---|---|---|
|札幌|1000円|42.2%|422円|
|仙台|2000円|29.9%|598円|
|東京|10000円|4.1%|410円|
|名古屋|5000円|7.8%|390円|
|大阪|6000円|6.8%|408円|
|福岡|4000円|9.1%|364円|
仙台の期待値が最も高くなるので、目隠しを外して雪が降っていたら「仙台」と答えるのが良いでしょう。

上記のようにベイズ推定は、限られた情報から定量的な確率を求めることができるため、不確定要素の多い現実世界の意思決定において有用なデータを得ることができます。

注意点としては、事前確率や尤度は分析者がドメイン知識等に基づいて与える必要があるため、どうしても分析者の主観が推定結果に組み込まれてしまいます。
（例えば上例では降雪日数を基に尤度を求めていますが、降雪日数は「1日のうち少しでも雪が降っていればカウント」という集計方法のため、実際に雪が降っている時間比を表しているわけではありません）

[Wikipediaにも記載されていますが](https://ja.wikipedia.org/wiki/ベイズの定理)、上記からベイズ推定は**主観確率**に基づく手法だと批判を受ける事もあり、尤度の設定（ベイズ統計モデリングにおいては回帰式や確率分布の選択）には慎重を期す必要があります
（とはいえ、他の手法でも主観が入ることは避けられない）

#### ※周辺尤度について
先ほど「周辺尤度$p(X)$は規格化で消去可能」と解説しましたが、消去せずに真面目に計算するとどうなるでしょうか？

周辺尤度に確率の加法定理と乗法定理を適用すると、以下のように事前確率と尤度の総和で表されることが分かります。

```math
p(X)=\sum_{j} p(X,Y)\\
=\sum_{j} p(X \mid Y) p(Y)\\
=\frac{29.1}{31}\frac{1}{6}+\frac{29.1}{31}\frac{1}{6}+\frac{20.6}{31}\frac{1}{6}+\frac{2.8}{31}\frac{1}{6}+\frac{5.4}{31}\frac{1}{6}+\frac{4.7}{31}\frac{1}{6}+\frac{6.3}{31}\frac{1}{6}\\
=0.37
```
この計算は先ほど規格化のために実施した計算と同じであり、結果的に周辺尤度を求めることは、規格化と同じ操作を行なっていることが分かります。

### 統計モデリングにおけるベイズ推定
統計モデリングにおいては、**ベイズ推定をモデルのパラメータ算出に使用**します。



|数式|上記解説における名称|ベイズ推定における名称|
|---|---|---|
|$p(Y｜X)$|条件付き確率 (Xを与えたときのYの確率)|事後確率（事後分布）|
|$p(X｜Y)$|条件付き確率 (Yを与えたときのXの確率)|尤度|
|$p(Y)$|周辺確率(Y)|事前確率（事前分布）|
|$p(X)$|周辺確率(X)|周辺尤度|
以降の解説では、「ベイズ推定における名称」を使用します。

## C. 回帰
前述のように、ベイズ統計モデリングにおいては明示的なモデルが必要となり、
そのモデルの構成要素となるパーツには、[前述の「A. 確率分布」（尤度関数）]()に加えて**「C. 回帰式」（説明変数と各パラメータの関係式）**が必要となります。

回帰式の形状として、ベイズ統計モデリングでは以下がよく使用されます（さらに複雑な形状も指定できますが、深いドメイン知識が背景にない場合、複雑な形状をフィッティングするのであれば**機械学習**や**ガウス過程回帰**を使用した方が良いと思います）
### 線形回帰

```math
y = 
```

### 多項式回帰

### ロジスティック回帰

別記事で紹介します

## D. 区間推定
### 確率分布の区間推定

# ベイズ統計モデリングの理論
ベイズ統計モデリングのハードルが高い理由として、[実装方法が記載された書籍]()と[PRMLのような理論のみが記載された書籍]()の中間的な情報が少ない事が挙げられるかと思います。

本記事ではこの**中間的な部分を埋める**ことを目指し、**ベイズ統計モデリング(MH法MCMC)による一般化線形モデルまでの理論を過不足なく説明し、スクラッチ実装したコードを併記する**ことを目標とします。

## 統計モデリング

## 尤度と最尤推定
### 尤度とは？
数々の初学者を混乱させる謎の概念「尤度」（尤度関数）ですが、[Wikipedia](https://ja.wikipedia.org/wiki/尤度関数)では以下のように定義されています

`ある前提条件に従って結果が出現する場合に、逆に観察結果からみて前提条件が「何々であった」と推測する尤もらしさ（もっともらしさ）を表す数値を、「何々」を変数とする関数として捉えたものである。`

何だかよく分かりませんね。
分からない大きな原因として、普段使わない「尤（もっともらしい）」という漢字の存在が大きいと考えているので、高校でも習う表現に言い換えたいと思います。

[前述のベイズの定理]()でも述べたように、

```math
\sum{}{}
```

**尤度 = ある前提条件が与えられた元で、データが観測される「条件付き確率」**
と理解すると分かりやすいかと思います。

後で詳細に解説しますが、事後確率は尤度とは逆に
**事後確率 = データが観測されたと言う条件のもとで、ある前提条件を満たす「条件付き確率」**
となります。

### 統計モデリングにおける尤度
ある確率分布が与えられた時、1個のデータが観測される確率は確率密度関数で表されます。

例えば、平均0、標準偏差1の正規分布から`2`という値が観測される確率は、以下のように表されます

```r
```

データは一般的に複数（ここではN個とする）存在するため、[前述の同時確率]()の定義から、**すべてのデータが観測される確率=尤度**は、前述の**確率密度関数の積**で表されます。

例えば平均5、標準偏差1の正規分布から生成された10個のデータ

```r
set.seed(1) # 乱数の種
MU_TRUE = 5.0  # 真の平均
S_TRUE = 1.0  # 真の標準偏差
N = 10  # データの個数
x = rnorm(n=N,mean=MU_TRUE,sd=S_TRUE)  # データ生成
```

に対し、平均muを-5〜15まで変化させた正規分布（簡単のため標準偏差は1で固定）それぞれに対する尤度を求めてみます

```r
```


muの値により尤度が変化しており、
尤度がパラメータmuに対して関数として求められる（=**尤度関数**）ことが分かります

上例では動かしたパラメータは平均mu（標準偏差を1で固定）のみでしたが、
標準偏差sも0.5〜1.5まで動かした場合、尤度は以下のようにmuとsの二次元のパラメータの関数となります

```r
```

### 最尤推定
[前述のように]()、**尤度=データが観測される「条件付き確率」**なので、
データに対して尤度が高いほど
**「データが観測される確率の高いモデル=当てはまりの良いモデル」**
とみなすことができます。

上記の考えに基づき、**尤度が最も高くなるパラメータの値**を採用するパラメータ推定法を、**最尤推定**と呼びます。

例えば前述の例においては、

[1次元の山の頂上]()
[2次元の山の頂上]()

のように、**尤度関数の山の頂上となるパラメータを選択**することで、最尤推定を実現することができます

### 正規分布モデルにおける最尤推定
ここからは数式

### 線形回帰モデルにおける最尤推定


※上記のように、機械学習に位置づけられることの多い「線形回帰」は正規分布＋線形関係を仮定した最尤推定と同一の式で表せ、一種の統計モデリングとみなすこともできます。
このあたりからも、**機械学習と統計モデリングの境界は曖昧**であることがわかります。

### 一般化線形モデル




### 最尤推定と過学習
[前述のように]()、**最尤推定はデータが少ないとき過学習**します。

この理由を、シンプルな正規分布モデル（パラメータ$\mu$と$\sigma$を持つ）において数式から解説します。

PRMLの数式から説明

http://racco.mikeneko.jp/Kougi/10a/IS/IS08pr.pdf

・分散が過小評価される（分散の期待値が真の分散の$\frac{N}{N/1}$倍に）
・平均がばらつく（平均の分散が$\sqrt{N}$に反比例）


上記のように、**最尤推定では少量サンプルにおいて**推定の確度が低くなり、少ないデータに過剰にフィットして真の分布からの誤差が大きくなる**「過学習」**状態となってしまいます。
（分かりやすいよう「真の分布」という表現を使いましたが、ベイズ統計学では好まれない表現であることにご注意ください）

よってバイアスの少ない分析を行うためには、この**「少量サンプルにおける確度の低さ」**を考慮した判定を行う必要があります。

#### 参考：推計統計学での「少量サンプルにおける確度の低さ」の考慮
推計統計学の分野では、サンプル数nによる平均や分散の変化を統計的に数式化することで、少量サンプルにおける確度の低さを考慮した検定がよく利用されます。
[F分布を使用した分散の比の検定](https://bellcurve.jp/statistics/course/9929.html)や、[t分布を使用した平均の差の検定](http://www.aoni.waseda.jp/abek/document/t-test.html)がその代表的な例です。

##### 例：t検定
平均が1、標準偏差が1のデータセットが2種類存在し、片方のサンプル数が5個、もう片方が50個のとき、
それぞれのデータセットで「真の平均(母平均)が0である」かを検定してみます。
感覚的には、サンプル数が50の方が標本から求めた「平均=1」の確度が高く、「平均は0でない」と結論づけられやすそうに見えます。

サンプル数n、標本平均$\bar{x}$、標本標準偏差s、母平均μのとき、以下の検定統計量tは自由度n-1のt分布に従います。

```math
t=\frac{(\bar{x}-\mu) \sqrt{n}}{s}
```
標本平均$\bar{x}$=1、標本標準偏差s=1、母平均μ=0を代入すると、tは以下のように求められます。

`サンプル数n=5`の時、t = √5 ≒ 2.236
`サンプル数n=50`の時、t = √50 ≒ 7.071

自由度n-1のt分布において上記の`t`を上回る確率が、本検定におけるp値(片側検定値)となります。
実用上は、-tを下回る確率も考慮するため、片側検定の2倍をp値とする両側検定がよく使用されます。

```r:サンプル数による平均値の検定(t検定)結果の変化
library(ggplot2)
MU <- 0  # 検定対象の母平均
BAR_X <- 1  # 標本平均
S <- 1  # 標本標準偏差

# サンプル数5のとき
N_1 <- 5  # サンプル数
t_1 <- (BAR_X-MU)*sqrt(N_1)/S # 検定統計量t
p_1 <- 2 * pt(t_1, N_1-1, lower=F)  # 両側検定のp値
ggplot(data=data.frame(X=c(-8,8)), aes(x=X)) +
  stat_function(fun=dt, args=list(df=N_1), color="blue") +
  geom_vline(xintercept = t_1) +
  labs(x='t', y='', title=paste('N=', N_1,', p_value=', p_1))

# サンプル数50のとき
N_2 <- 50
t_2 <- (BAR_X-MU)*sqrt(N_2)/S # 検定統計量t
p_2 <- 2 * pt(t_2, N_2-1, lower=F)  # 両側検定のp値
ggplot(data=data.frame(X=c(-8,8)), aes(x=X)) +
  stat_function(fun=dt, args=list(df=N_2), color="red") +
  geom_vline(xintercept = t_2) +
  labs(x='t', y='', title=paste('N=', N_2,', p_value=', p_2))
```
**・n=5の時のt分布形状とt検定結果**
<img width="600" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/892a8d25-60f9-8f0b-f33a-1bf3b0479f30.png">
**・n=50の時のt分布形状とt検定結果**
<img width="600" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/7b274b59-0b1c-4888-9172-0c46ef279275.png">

上図の黒い縦線(上記の`t`)を上回る確率が、検定におけるp値となります。
有意水準を0.05に設定すると、

・n=5のときはp値=0.089>0.05より「平均が0である」が棄却されない（有意差なし）
・n=50のときはp値=5.1e-9<0.05より「平均が0である」が棄却される（有意差あり）

という結果となり、当初の想定通り**「少量サンプルでは確度が低いので、同じ統計値でも有意差ありと判定されずらい」**という

t検定のような推計統計学的アプローチは便利かつ一般にも浸透した手法ですが、「複雑なモデルでの適用が難しい」「p値の解釈が難しい」等が、課題としてよく挙げられます。

そこで、全く異なるアプローチで「**少量サンプルにおける確度の低さ**」を考慮し、かつ上記の課題をクリアできる手法が、ベイズ推定に基づいたモデリング、すなわち**ベイズ統計モデリング**となります。


## ベイズ統計モデリング
最尤推定
### ベイズの定理による事後分布の推定

### 最尤推定に対するベイズ推定の優位性
→最尤推定はサンプル数が少ない時過学習しやすい

事前分布が正則化項の役割を果たす

### ベイズ推定の難しさ
積分が難しい

https://qiita.com/gen_nospare/items/6d9c81e0718e9a5a1db1#はじまり



## マルコフ連鎖モンテカルロ法（MCMC）

### ・メトロポリス-ヘイスティングスアルゴリズム（MH法）

### ・ギブスサンプリング

### ・HMC

### ・その他のMCMC法

### 回帰と組み合わせたベイズ統計モデリング

### MCMCのロバスト性向上のための工夫

[後述のStanでの実装例]()においても、重要な設定項目として登場します。

[StanとRでベイズ統計モデリング46ぺーじの]()の記載を基に決め方を書く

#### バーンイン期間
#### チェーン
#### 間引き

## ベイズ信用区間とベイズ予測区間の求め方
[前述のように]()、ベイズ統計モデリングの出力として求まる区間推定には、パラメータの存在範囲を示す**「信用区間」**と、応答変数自体の存在範囲（ばらつき）を示す**「予測区間」**の2種類が存在します。

具体的な算出方法を紹介します。
### ・ベイズ信用区間
[前述のように]()、信用区間（ベイズ信用区間）とは「モデルのパラメータの存在範囲を区間推定したもの」を表します。

「モデルのパラメータの存在範囲」は事後分布そのものであるため、信用区間は事後分布を区間推定で求める事ができます。
例えば[前述の例]()においてパラメータmuとsigmaの信用区間を区間推定すると、

[muの区間推定]()
[sigmaの区間推定]()

となります。

#### MCMCにおけるベイズ信用区間
MCMCを使用して事後分布を求めた場合、MCMCサンプルは事後分布に従っているため、MCMCサンプルをパラメータの値の順に並べ、端部を除いて区間推定の割合だけデータを選択

例えば[前述の例のように]1000個のサンプルにおいて95%信用区間を求めたい場合、パラメータmu, sigmaそれぞれ昇順にMCMCサンプルを並べ替え、25番目と975番目のサンプル（全体の95%のデータが入る範囲）の値を区間推定の上下限として求める事ができます。

[muの区間推定(25番目~975番目のサンプル)]()
[sigmaの区間推定(25番目~975番目のサンプル)]()

### ・ベイズ予測区間
応答変数の存在範囲（ばらつき）を表す予測区間を求めるためには、さらに一手間かける必要があります。
[前述のように]()**予測区間は実用上重要**な分析結果となるため、長いですがご一読いただければと思います。
#### 参考）最尤推定における予測区間
最尤推定において各パラメータは唯一の値に定まるため、予測分布は
「定まったパラメータにおけるモデルの確率分布」
として単純に求めることができました。

例えば[前述の例]()においてパラメータはmu=, sigma=と定まったため、予測分布は平均、標準偏差の正規分布として求める事ができます

[前述の最尤推定における予測分布]()

よって予測区間（95%予測区間）はこの正規分布における下位2.5%~上位2.5%の区間として、簡単に求める事ができます。

#### ベイズ統計モデリングにおける予測区間
ベイズ統計モデリングにおいてパラメータは唯一の値ではなく、幅をもった確率分布（事後分布）として求まります。
よって予測分布（事後予測分布）は

「あるパラメータにおけるモデルの確率分布」を、「そのパラメータの存在確率（事後分布）」で積分したもの

として計算する必要があります。

例えばパラメータμのみを持つ正規分布(標準偏差は1で固定)をモデルの確率分布としたとき、以下のように求められます
[畳み込みぽいgifアニメ]()
（信号処理に詳しい方は、モデル確率分布とパラメータ事後分布の「畳み込み積分」とみなすと理解しやすいかと思います）

これを数式で表すと、以下のように記述できます（[こちらの書籍](https://www.kyoritsu-pub.co.jp/bookdetail/9784320112421)参照）

```math
p_{pred}(y \mid Y) =　\int p(y \mid \theta) p(\theta \mid Y) d\theta
```

```math
\left\{\begin{array}{ll}
p_{pred}(y \mid Y):事後予測分布\\
p(y \mid \theta):あるパラメータにおけるモデルの確率分布\\
p(\theta \mid Y):パラメータの事後分布\\
\theta:パラメータの集合(例.正規分布の\mu, \sigma)\\
Y:データ全体（各データの応答変数sepal.lengthの集合）\\
y:応答変数(例.sepal.length)\\
\end{array}\right.
```
※積分範囲はパラメータの値域

例えば[前述の例]()においてパラメータmuとsigmaの事後分布から事後予測分布を求めると、以下のような式で求められます

```math
\int_{0}^{\infty} \int_{-\infty}^{\infty} Normal(y \mid \mu,\sigma) p(\mu,\sigma \mid Y) d\mu d\sigma
```

```math
\left\{\begin{array}{ll}
Normal(y \mid \mu,\sigma):平均\mu,標準偏差\sigmaの\\正規分布における確率密度関数\\
p(\mu,\sigma \mid Y):パラメータの事後分布\\
\end{array}\right.
```

[事後分布の積分計算だけでも大変]()だったのに、それをさらに積分する事後予測分布の算出が、いかに大変となるかは想像がつくかと思います。

#### MCMCにおける予測区間
一方で**MCMCサンプル**の形で事後分布を求めていれば、より**簡単に事後予測分布を求める**事ができます。

MCMCでは、モデルの確率分布
$p(y \mid \theta)$
は事前に式として与えており、
パラメータの事後分布
$p(\theta \mid Y)$
はMCMCサンプルとして求まるため、
パラメータθの積分をMCMCサンプルの和で置き換えることで、事後予測分布の近似値を求める事ができます。

例えば[前例]()において
i番目のMCMCサンプルのパラメータμの値を μ[i]
i番目のMCMCサンプルのパラメータσの値を σ[i]
とすると、事後予測分布

```math
\int_{0}^{\infty} \int_{-\infty}^{\infty} Normal(y \mid \mu,\sigma) p(\mu,\sigma \mid Y) d\mu d\sigma
```
は以下の式で近似することができます

```math
\sum_{i}Normal.Rand(y \mid \mu[i],\sigma[i])
```
$Normal.Rand(y \mid \mu[i],\sigma[i])$は、「平均μ[i], 標準偏差σ[i]の正規分布に従う乱数」を表しており、
μ,σのMCMCサンプルμ[i],[i]を使用することでパラメータの事後分布(積分内第2項)を
パラメータμ[i],σ[i]に従う確率分布から乱数を生成することでモデルの確率分布(積分内第1項)を
再現しています。

[MCMCサンプルの2次元ヒストグラム（sns.jointplot的なのが分かりやすそう）から1個選択し、「そこから生成した正規分布から乱数を生成する」という操作を複数（Stanでは全てのサンプル分）繰り返し、生成した乱数のヒストグラムを予測分布とする　という図]()

サンプルiの選び方ですが、Stanのデフォルトでは、全ての事後分布のMCMCサンプル（NSample=(iter-warmup) × chain個）を使用して

```math
\sum_{i=1}^{NSample}Normal.Rand(y \mid \mu[i],\sigma[i])
```
として求めているようです。

**回帰的要素（線形予測子）を含む場合**の事後予測分布算出はさらに一手間加える必要があるため、**[回帰における実装例]()の紹介時に別途解説します**
→馬場氏本174ページ

## ベイズ統計モデリングの諸知識
以上でベイズ統計モデリングの基本的な理論に関する解説は終わりとなりますが、実用上知っておいた方が良い知識について下記します

### ・グラフィカルモデル


### 事前分布が与えられたときの挙動

事前分布を変更しても事後分布が大きく変わらないことを調べる作業を、「感度分析」と呼びます。

### 収束する確率分布

収束しない

## 応用的なベイズ統計モデリング
ベイズ統計モデリングに様々な工夫を加えることで、より複雑な現象をモデルで表現することが可能となります。
今回はこれら応用的なモデルの中で、実用上使用される事の多い以下のモデルを紹介します

|||
|---|---|
|階層ベイズモデル|グループを持つデータの解釈・予測が可能となる|
|状態空間モデル|時系列データの解釈・予測が可能となる|

### 階層ベイズモデル
「どのグループにも属さない場合=未知のグループ」（機械学習における「欠損値」に相当）の推定ができることです。

一般的な機械学習アルゴリズムは欠損値がある場合、欠損値を無理矢理何かしらの値で埋める処理（データクレンジングの一種）が必要となるため、このようなデータをそのまま扱える階層ベイズの存在は、機械学習に対するベイズ統計モデリングのメリットの一つとなっています。

余談ですが、機械学習の中でも[LightGBM等の木構造アルゴリズムは欠損値をそのまま扱うことができ](https://upura.hatenablog.com/entry/2019/10/29/184617#1-欠損値をそのまま扱える)、Feature Importance等の解釈に使用できるアルゴリズムを含んでいることも含め、ベイズ統計モデリングのお株を一部奪う優れたアルゴリズムであることが伺えます。

別記事で紹介します

### 状態空間モデル

https://twitter.com/kilometer00/status/1470740948410056716?t=Yx3jfttTABCmH0-vZzQUHQ&s=19

別記事で紹介します

# 参考書籍

## 学習ロードマップ

## 個別の書籍紹介

###

### ・パターン認識と機械学習（PRML）
ご存じの方も多いかと思いますが、数々のデータサイエンティスト・機械学習エンジニアの心を折ってきた名著です。

今まで紹介した実践的な書籍と比べて理論寄りで難解な内容ですが、ベイズ理論と機械学習との関係も含めて網羅的に触れられているので、ベイズ統計モデリングの全体像を理解するための教材としては適した書籍だと思います。

また「機械学習」と銘打ってはいますがベイズ理論が内容の中心となっており、執筆された2006年当時のベイズ統計モデリングへの期待度が垣間見え、[冒頭で触れた機械学習と比べた普及度の低さ]()も、[このあたりの問題が解消されれば]()盛り返すではと言う期待が持てる内容となっています。

、以下を

・前述の書籍を一通り読破する
・統計モデリングだけでなく、機械学習の知識も一通り身につける（Scikit-Learnに含まれるようなテーブルデータ向け機械学習アルゴリズムがメインなので、深層学習の知識は不要）



# ベイズ統計モデリング向けライブラリの紹介
前述のように、ベイズ統計モデリングを実装するためには**確率的プログラミング言語**を使うことが一般的です。

主な確率プログラミング言語の一覧を下記します。

|名称|フレームワーク|概要|GitHub Star数 (2022/1)|
|---|---|---|---|
|RStan|R|StanのRインターフェイス||
|PyStan|Python|StanのPythonインターフェイス||
|PyMC|Python|||
|TensorFlow Probability (TFP)|Python|||
|Pyro|Python|||
|Numpyro|Python|||

**Rを使用する場合、RStan**が主流となっているのでこれを選択するのが無難かと思います。

**Pythonを使用する場合**、2022年時点ではライブラリが乱立していて「これ」と言えるライブラリを特定することが難しい状況です（PyStanやPyMCが比較的古くから存在し、PyroやTFP等の深層学習ベースのライブラリが2017年以降に登場）
「勉強したライブラリが5年後には開発終了していた」という事態もありうるので、このリスクを把握した上で好きなライブラリを選択いただければと思います。

# 実装
まず最初にお伝えしたい事として、**初学者はR＋Stanでの実装をお薦めします**。
理由は、「Pythonよりも環境構築が簡単で情報も多い」ことです。

[過去記事](https://qiita.com/c60evaporator)を見て頂ければ分かりますが、全投稿記事の2/3をPythonが占めるほどPython信者な私でも、以下の理由から**「Pythonで初学者が実装するのは修羅の道」**だと感じて諦めました。

・環境構築が大変（[前述のように]()ハマりやすい操作が多い）
・メジャーな書籍はRでの実装を前提としているものが多い
・書籍以外の実装に関する情報も少ない（PyStanやPyMC、Pyro等は断片的な情報が多く、網羅的にまとめられたサイトはほぼ存在せず）

Rであれば半デファクトスタンダードとなっている**RStan** (StanのRインターフェイス)が存在し、参考書籍も豊富に存在するので、**勉強が目的であればRを使用した方が効率的に学習できる**かと思います。
（Rの基本文法に関しては以下の記事が参考になります。Pythonと似た部分が多く、Python経験者であれば労せず会得できるかと思います）

https://qiita.com/zettsu-t/items/4e52a877f92c5c05caf8

本記事では以後、**RStanでの実装例**を紹介していきます
（Pythonでの実装例は、現時点でのベストプラクティスを模索した上で別途記事にします）

## 環境構築
Mac（M1）でのRおよびStan環境構築は以下で別途記事にしました。
Windowsでも「Brewを使わずインストールしたい場合」に記載されているフローで環境構築可能なので、参照頂ければと思います

[記事]()

公式の環境構築手順ドキュメントも参照ください

https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started-(Japanese)

また環境構築に使用したR Notebookのコードを下記にアップロードしております（2022/1最新のOSで動作確認済）
・[M1 Mac環境構築コード]()
・[Windows10 環境構築コード]()

## モデルの選び方
[前述のように]()、ベイズ統計モデリングは主に以下の用途で使用されます

**1. 予測**（主にテーブルデータ）
**2. 異常検知**
**3. 時系列分析**（状態空間モデル）

まずは上記の「用途」とデータの特性、ドメイン知識に基づき、大まかなモデルの種類を選択する必要があります。

もう少し具体的な情報がないと選択が難しいかと思うので、「用途」「応答変数の種類」「説明変数の種類」「説明変数の数」に基づき、**選択すべきモデルのチートシート**を作成しました。

[チートシート]()

※私独自に作成したものなので、間違い等あればご指摘頂ければと思います。

モデルの種類毎の**実装例**のリンクをまとめて下記します。
詳細はリンク先を算出ください（1〜5までの実装知識はStanを扱う上で最低限必要かと思うので、ご一読頂ければと思います）

|用途|応答変数の種類|説明変数の種類|説明変数の数|モデル名称と実装法リンク|
|---|---|---|---|---|
|**1.予測**|連続|数値|1変数|[2. 単回帰モデル]()|
|**1.予測**|連続|数値|多変数|[【別記事】3. 重回帰モデル]()|
|**1.予測**|連続|カテゴリ|1変数|[【別記事】4. 分散分析モデル]()|
|**1.予測**|連続|カテゴリ＋数値|多変数|[【別記事】5. カテゴリ変数を含む重回帰モデル](),<br>[【別記事】6. 交互作用を持つ重回帰モデル](),<br>[【別記事】7. 階層ベイズモデル]()|
|**1.予測**|離散(0 or 1)|数値 or カテゴリ|1 or 多変数|[【別記事】ロジスティック回帰]()|
|**1.予測**|離散(分母が変動)|数値 or カテゴリ|1 or 多変数|[【別記事】二項ロジスティック回帰]()|
|**1.予測**|離散(発生率が低い)|数値 or カテゴリ|1 or 多変数|[【別記事】ポアソン回帰]()|
|**1.予測**|時間間隔|数値 or カテゴリ|1 or 多変数|[【別記事】時間間隔のモデル化]()|
|**2.異常検知**|連続|なし|なし|[1. 確率分布の当てはめ]()|
|**2.異常検知**|離散(分母が変動)|なし|なし|[【別記事】二項分布の当てはめ]()|
|**2.異常検知**|離散(発生率が低い)|なし|なし|[【別記事】ポアソン分布の当てはめ]()|
|**2.異常検知**|時間間隔|なし|なし|[【別記事】時間間隔のモデル化]()|
|**2.異常検知**|連続 or 離散|数値 or カテゴリ|1 or 多変数|[2〜5. 回帰と組み合わせた異常検知]()|
|**3.時系列分析　　**|連続|時間（＋数値orカテゴリ）|1 or 多変数|[【別記事】状態空間モデル]()|
※記事が長すぎてMacに「電力不足です」と怒られたので、ユースケース3以降は別記事に分割しました。

## 手順概要
大まかなモデルの種類が定まったら、実際に実装を進めていきます。
[前述]()のように、ベイズ統計モデリングは以下の手順でモデルを構築します。

**手順1. 現象の知識に基づき確率モデル（主に「A.確率分布」と「C.回帰」の組み合わせ）を構築する**
**手順2. 取得したデータとベイズの定理に基づき、モデルのパラメータの事後確率分布を計算する（学習）**
**手順3. データに対するモデルの当てはまりを評価する**

以下、各手順の概要を解説します。

### 手順1. 現象の知識に基づき確率モデルを構築
大まかなモデルの種類は[モデルの選び方]()の項で選択済ですが、
さらに詳細なモデル形状を定めるため、[前述の]()
**・線形予測子**（回帰的要素の線形部分）
**・リンク関数**（回帰的要素の非線形部分）
**・確率分布**
を、**詳細なデータ分析に基づき特定**する作業を行います。

### 手順2. 取得したデータとベイズの定理に基づき、モデルのパラメータの事後確率分布を計算
手順1で作成したモデルとデータをStanに入力してMCMCサンプルを生成することで、**各パラメータの事後分布を算出**します。

### 手順3. データに対するモデルの当てはまりを評価
得られたMCMCサンプルに各種処理を加えることで、
**・収束判定**（学習が成功したか）
**・信用区間と予測区間の算出**（予測や解釈において重要な情報）
**・各種グラフによる可視化**
等を実施し、モデルの妥当性確認や可視化、および目的とする分析結果の抽出を実現します。

以降は、モデルの種類ごとに実装法を解説していきます。

<br>

# ユースケース1. 確率分布の当てはめ
まずは最もシンプルな例として、データに確率分布を当てはめる例を紹介します。

本ユースケースでは、[iris（アヤメ）データセット](https://note.nkmk.me/python-scikit-learn-svm-iris-dataset/)の`sepal_width`変数（がくの幅）に確率分布を当てはめてみます

![9cede6e3-0932-430a-a17e-d30025eb2b02.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/27bc8bfb-0dd4-b5e2-e506-8989a2c5e081.png)

## 手順1. 確率モデルの構築
本ユースケースでは説明変数を持たない（回帰的要素がない）ため、確率分布を当てはめるのみです。
よって**当てはめる確率分布の種類を確定**させます。

分布形状を判断するための前準備として、まずはヒストグラムによる可視化を行います

```r:ヒストグラムによる可視化
# データ読込（irisデータセットのsepal_width）
sepal_width <- iris$Sepal.Width
# ヒストグラム描画
hist(sepal_width)
```
![000003.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/60c1e100-7289-d5ea-7009-23e30d7a618a.png)

左右対称の分布で、定性的には正規分布に近い形状に見えます。
どの種類の確率分布を当てはめるかを定量的に検討する方法として、

・[こちらの記事](https://qiita.com/c60evaporator/items/fc531aff0cdbafac0f42#本ツールによる判断方法-1)のように最尤推定でAICやBICの低くなる確率分布を選択
・実際に複数の候補によるベイズ統計モデリングを実施して、AICやBIC等の指標で比較

等が考えられますが、今回は分布形状から正規分布であるだろうという仮定に基づき、**[シャピロ・ウィルク検定](https://qiita.com/c60evaporator/items/fc531aff0cdbafac0f42#ユースケース1の解決策正規性検定とqqプロット)で正規分布であるかを判定します**

Rではシャピロ・ウィルク検定は`shapiro.test(x=)`と打つだけで簡単に実現できます。

```r:sepal_widthをシャピロウィルク検定
# シャピロウィルク検定
shapiro.test(x=sepal_width)
```

```:検定結果
Shapiro-Wilk normality test

data:  sepal_width
W = 0.98492, p-value = 0.1012
```

P値 > 0.05より、「正規分布である」という仮説は棄却されず、概ね正規分布に近い形状となっていることがわかります。
（本来は[こちらの例](https://qiita.com/c60evaporator/items/fc531aff0cdbafac0f42#ユースケース1の解決策正規性検定とqqプロット)のようにQQプロットも見て判断することが望ましいですが、今回は割愛します）

上記により、**sepal_widthの分布は正規分布である**と判断し、平均μ, 標準偏差σの正規分布モデルを構築することとします。

### モデル式とグラフィカルモデルの定義
上記で定めたモデルのモデル式は以下のようになります

```math
Y[n] \sim Normal(\mu,\sigma)
```
グラフィカルモデルは以下のようになります。

[グラフィカルモデルの図]()

上記のμとσをパラメータとし、MCMCで事後分布を求めます

## 手順2. MCMCでパラメータの事後分布算出
ここからはStanを使い、MCMCでパラメータの事後分布を求めていきます。
基本的には[こちらの書籍](https://www.kspub.co.jp/book/detail/5165362.html)の手順に従います。

### 2-1. MCMC実行
StanでMCMCを実行するためには、以下の2種類のファイルを作成する必要があります。

|ファイル名称|拡張子|役割|
|---|---|---|
|Stanファイル|.stan|モデル式、パラメータ、入力データを定義する|
|Rファイル|.Rまたは.Rmd|Stanを呼び出してMCMCを実行する＆結果を確認する|
それぞれ解説します

#### Stanファイル
Stanファイルには、手順1で決めたモデルに基づき、

・データの定義
・パラメータ
・モデル式（場合によっては事前分布も）
（・予測分布の算出式 → 必要な場合のみ記載）

をブロックに分け、以下のように記載します。

```kotlin:Stanファイルの基本文法
data {
  //データの定義
}

parameters {
  //MCMCで推定したいパラメータの定義
}

model {
  //モデル式（尤度関数）の定義
  //(事前分布の定義（省略可）)
}

generated quantities {
  // 予測分布の記述
}
```
※他にもfunctions(自作関数)、transformed data(データ変換)、transformed parameters(パラメータ変換)等のブロックがありますが、現時点では使用しないので割愛します。

今回の例では、以下のように記述します

```kotlin:usecase1_fit_distribution.stan
// dataブロック（データの定義）
data {
  int N;//データ数
  vector[N] sepal_width;//データ
}

// parametersブロック（パラメータの定義）
parameters {
  real mu;//平均
  real<lower=0> sigma;//標準偏差
}

// modelブロック（モデル式を記述、事前分布は省略）
model {
  for (i in 1:N){
    sepal_width[i] ~ normal(mu, sigma);
  }
}

// generated quantitiesブロック（予測分布を記述）
generated quantities {
  vector[N] pred;
  for (i in 1:N){
    pred[i] = normal_rng(mu, sigma);
  }
}
```

ブロック毎に解説します。

##### ・dataブロック
dataブロックには、入力するデータの定義を記載します。
最低限記載が必要な内容として、以下が挙げられます。

・データ数
・使用する変数（説明変数＋応答変数、今回は応答変数のsepal_widthのみ）

注意点として、**使用する変数の名称を[後述のRファイルにおけるlistの要素名]()と揃える**必要があります。
下記の例では、Rファイル側でもデータ数に`N`、応答変数に`sepal_width`という要素名を指定する必要が生じます。

```kotlin
data {
  int N;//データ数
  vector[N] sepal_width;//応答変数
}
```
「使用する変数」は単一の変数ではなく、データ数だけ要素が存在するため、上記のようにベクトル形式で指定します。

##### ・parametersブロック
parametersブロックには、推定したいパラメータの一覧を記載します。
今回の例では、[手順1で決めたモデル式]()に基づき、μとσの2パラメータを定義します

```kotlin
parameters {
  real mu;//平均
  real<lower=0> sigma;//標準偏差
}
```
`real`という名称は実数を表しており、cやpythonにおけるfloatに相当します。
また、`<lower=0>`の部分は値域の制限を指定しており、本例では標準偏差はマイナスとなることがないので、下限0を指定しています。

`lower`の代わりに`upper`と記載すれば上限を指定でき、`<lower=0, upper=1>`のように指定することで、上下限両方を指定することも可能です。

##### ・modelブロック
modelブロックには、モデル式を記載します。
今回の例では、[手順1で決めたモデル式]()（sepal_widthが平均mu、標準偏差sigmaの正規分布に従う）

```math
Y[n] \sim Normal(\mu,\sigma)
```

をStanの記法に従い記述します。

```kotlin
model {
  for (i in 1:N){
    sepal_width[i] ~ normal(mu, sigma);//sepal_widthは平均mu、標準偏差sigmaの正規分布に従う
  }
}
```
※`normal()`に指定する引数が分散ではなく標準偏差であることに注意してください

##### ※ベクトル化について

上例ではfor文でデータ数分のデータ生成過程を記述していますが、
以下のようにforを使わずに一括で記述する**ベクトル化**という記法も存在します。

```kotlin:上のモデル式をベクトル化して記載
model {
  sepal_width ~ normal(mu, sigma);//sepal_widthは平均mu、標準偏差sigmaの正規分布に従う
}
```

一般的にベクトル化は速度がやや向上し、記載行数を減らすこともできますが、ベクトル化をしない方がMCMCのアルゴリズムに近い記載となっており、可読性が高いとみなすこともできます。

後者がMCMCのアルゴリズムに近い記載と言える理由ですが、[前述のように]()各MCMCサンプルにおける対数事後確率`lp__`=$\log p(\theta \mid Y)$は、上例では以下の式で表されます。

```math
\log p(\theta \mid Y)=\log p(Y \mid \theta)+\log p(\theta) \cdots ベイズの定理より\\
=\sum_{i=1}^{N} \log Normal(Y[i] \mid \mu,\sigma)  +\log p(\mu,\sigma) \cdots 対数尤度は確率密度関数の対数の和
```

```math
\left\{\begin{array}{ll}
\log p(Y \mid \theta):尤度\\
Normal(Y[n] \mid \mu,\sigma):平均\mu,標準偏差\sigmaの\\正規分布におけるデータY[n]の確率密度関数\\
\log p(\theta):事前分布\\
Y[i]:データ（各データの応答変数sepal.length）\\
\end{array}\right.
```
上式より、各MCMCサンプル（個々にパラメータmuおよびsigmaを持つ）における`lp__`は、
「モデル式から求めた対数確率密度関数の総和」+「事前分布の対数」
で求められる事が分かります。

また[こちらの書籍](https://www.kyoritsu-pub.co.jp/bookdetail/9784320112421)によると、Stanにおいて記号`~`は、内部的には「`lp__`に右辺を足し算する」という処理が行われています。

よってfor文でデータ数分だけ「データ ~ 確率分布」という処理を繰り返す後者の（ベクトル化をしない）記法は、「対数事後確`lp__`率にモデル式から求めた対数確率密度関数の総和を足す」という上記処理を忠実に表現していると言え、より内部アルゴリズムに近い可読性の高い記法とみなせます。
（「事前分布足しとらんやんけ！」と思われる方もいるかもしれませんが、Stanにおいて事前分布非指定時は十分に広い一様分布が指定されるため、パラメータの値によらず事前分布の値が一定となり、実際のMCMCアルゴリズムで使用される`lp__`の偏微分への影響がゼロとなるため、事前分布の影響は無視できるそうです。事前分布を指定する場合に関しては[後述]()します）

どちらの記法を採用するかは目的に合わせ選択頂ければと思います（**本記事では**以降、基本的には**ベクトル化記法で統一**します）

##### ※事前分布の指定法
上記の例では事前分布は指定されていない（デフォルトの広い一様分布=無情報事前分布が適用される）ですが、
modelブロックに以下のように事前分布を指定することができます。
パラメータごとに指定する必要があることにご注意ください。

```kotlin
model {
  for (i in 1:N){
    sepal_width[i] ~ normal(mu, sigma);//sepal_widthは平均mu、標準偏差sigmaの正規分布に従う
  }
  mu ~ normal(0, 1000);//muの事前分布
  sigma ~ normal(0, 1000);//sigmaの事前分布
}
```
なお、「事前分布をモデル式と同じmodelブロックに記述する」ことに違和感を感じられる方もいるかもしれませんが、[前述のように]()事前分布も、各MCMCサンプルにおいて内部的に対数事後確率`lp__`に足し合わされる対象となっており、modelブロック内で記号`~`の右辺に置かれることは、内部アルゴリズムに適合した記法であると言えます。

上記に基づき、以下のようなアルゴリズムそのものにより近い（`lp__`に対数確率密度関数の総和と事前分布の対数を足す）**「対数密度加算文」**という記法を使用することも可能です

```kotlin
model {
  for (i in 1:N){
    target += normal_lpdf(sepal_width[n] | mu, sigma);
  }
  target += normal_lpdf(mu | 0, 1000);
  target += normal_lpdf(sigma | 0, 1000);
}
```
上記の`target`が対数事後確率`lp__`を表しています。

##### ・generated quantitiesブロック
generated quantitiesブロックには、事後予測分布（予測区間の算出に使用）の計算方法を記述します。
[前述のように]()、予測分布は

```math
\sum_{i=1}^{NSample}Normal.Rand(y \mid \mu[i],\sigma[i])
```
※ $Normal.Rand(y \mid \mu[i],\sigma[i])$は、「平均μ[i], 標準偏差σ[i]の正規分布に従う乱数」を表す

から求まります。Stanではこの式に基づき、以下のように事後予測分布生成方法を記述します。

```kotlin
generated quantities {
  // 事後予測分布を得る
  vector[N] pred;
  for (i in 1:N){
    pred[i] = normal_rng(mu, sigma);
  }
}
```
上記の`pred[i] = normal_rng(mu, sigma)`の部分で、パラメータのMCMCサンプルから正規分布に基づく乱数をNSample個
（=(iter-warmup) × chain個）生成し、事後予測分布を近似的に求めています。

注意すべきはfor文で、上記の事後予測分布をデータ数N回分だけ繰り返して求める処理となっています（事後予測分布のMCMCサンプルがN × NSample個生成する）
必ずしもN回繰り返す必要はないかと思われますが（[回帰の例]()参照）、今回のように単純に確率分布を当てはめるケースでは[後述の]()`ppc_hist()`関数で使いやすくするためか、慣例上N回繰り返して事後予測分布を求める事が多いようです。

#### Rファイル
Rファイル側には、以下の内容を記載します

・パッケージ読込(RStan)
・計算高速化のための記述(コンパイルファイルの都度保存＋計算並列化)
・データをStanに読み込める形式(list形式)にまとめる
・MCMC実行(`stan()`メソッド)

```r:StanでMCMCによりパラメータの事後分布算出
# パッケージ読込
library(rstan)

# 計算高速化
rstan_options(auto_write=TRUE)  # コンパイルファイルの保存
options(mc.cores = parallel::detectCores())  # 計算並列化

# list形式にデータをまとめる（stanファイルのdataブロックと名称を揃える）
N <- nrow(iris)  # データ数
data_list <- list(sepal_width = iris$Sepal.Width, N = N)
data_list

# MCMC実行
mcmc_result <- stan(
  file = "./stan/usecase1_fit_distribution.stan", # Stanファイルのパス
  data = data_list, # 対象データ
  seed = 1,         # 乱数シード
  chains = 4,       # 初期値の個数（全初期値で近い結果となれば収束と判断）
  iter = 2000,      # サンプリングの繰り返し数
  warmup = 1000,    # バーンイン期間（収束前と見なして捨てるサンプル数）
  thin = 1          # 間引き数（1なら間引きなし）
)
```
上記コードを実行し、完了するまで待ちます（PCスペックにより変わりますが、数10秒〜数分掛かるかと思います）

##### ※計算高速化のための記述について
`rstan_options(auto_write=TRUE)`の部分は、一度コンパイルしたファイル（rds形式）を保存することを指定しており、TRUEとすることで2回目以降の実行が高速化されます（デメリットとして保持するファイルサイズが増えます）

`options(mc.cores = parallel::detectCores())`の部分は、Stan実行時にPCのコア数を自動検出した上で、並列計算を実行します。ChainごとのMCMCサンプル取得は独立におこなえるため、例えば`chains=4`を指定した場合、4コアを使用して並列でMCMCサンプルを取得します。

### 2-2. MCMC結果の概要を確認
`print()`関数で、MCMC結果の概要（各パラメータの推定結果）を確認します。

```r:MCMC結果の概要を表示
options(max.print=2000) # printの表示上限を増やす(lp__が表示されるように)
print(
  mcmc_result,                  # MCMCサンプルの結果
  probs = c(0.025, 0.5, 0.975)  # 中央値と95%信用区間を出力
)
```

```:結果
           mean se_mean   sd  0.5%  2.5%   50% 97.5% 99.5% n_eff Rhat
mu         3.06    0.00 0.03  2.97  2.99  3.06  3.13  3.15  2798    1
sigma      0.44    0.00 0.03  0.38  0.39  0.44  0.49  0.51  2853    1
pred[1]    3.04    0.01 0.45  1.94  2.18  3.05  3.92  4.19  3432    1
pred[2]    3.07    0.01 0.45  1.86  2.18  3.07  3.95  4.18  4157    1
  :
pred[150]  3.06    0.01 0.44  1.91  2.21  3.07  3.92  4.16  3922    1
lp__      48.26    0.02 0.95 44.36 45.65 48.56 49.20 49.23  1825    1
```
表示された結果の**列名**は、以下のように解釈します

|列名|内容（特に重要な列は太字）|
|---|---|
|一番左の列|**推定したパラメータの名称(後述)**|
|mean|パラメータ事後分布の平均|
|se_mean|パラメータ事後分布の標準誤差|
|sd|パラメータ事後分布の標準偏差|
|0.5%|**99%信用区間の下限**|
|2.5%|**95%信用区間の下限**|
|50%|事後分布のメディアン|
|97.5%|**95%信用区間の上限**|
|99.5%|**99%信用区間の上限**|
|n_eff|実効MCMCサンプル数([こちらの書籍](https://www.kyoritsu-pub.co.jp/bookdetail/9784320112421)では100以上推奨)|
|Rhat|**収束判断のための指標**(後述)|
信用区間の上下限は[後ほど使用するので]()、特に重要な指標として認識いただければと思います。

表示された結果の**行名(推定したパラメータ名)**は、以下のように解釈します

|パラメータ名|内容（特に重要な列は太字）|
|---|---|
|mu|平均パラメータmu|
|sigma|標準偏差パラメータsigma|
|pred[i]|事後予測分布(`generated quantities`ブロックで計算)|
|lp__|対数事後確率([前述]())|

## 手順3. モデルの評価
MCMCによって構成されたモデルを各種手法で評価し、モデルの妥当性を評価したり、各種解釈を得ます。
### 3-1. トレースプロットによる収束の確認
まず確認すべき事項として、**MCMCサンプルの収束**が挙げられます。

収束を判断するためには、MCMCサンプルが事後分布を再現する定常状態に至っており、かつどのChainでも同様の結果となっている事を確認する必要があります。

実用上は**トレースプロット**でMCMCサンプルの変動を可視化し、以下①〜③の条件を満たすかを確認することが

①全てのパラメータで[前述の]()**Rhat < 1.1**を満たす
②トレースプロットが**一定の範囲で振動**し続けていること
③トレースプロットが**全てのchainで同様の動き**をしていること

RStanでは`traceplot()`メソッドでトレースプロットを描画できます。

```r:トレースプロットの可視化
# トレースプロット（バーンイン期間を含まない）
traceplot(mcmc_result, pars = c("mu", "sigma", "lp__")) +
  labs(title="Without warmup")
# トレースプロット（バーンイン期間を含む）
traceplot(mcmc_result, inc_warmup=T, pars = c("mu", "sigma", "lp__")) +
  labs(title="Including warmup")
```
**・トレースプロット（バーンイン期間を含まない）**
<img width="600" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/196487e9-c4f6-473e-e1b0-4f3d04e72e09.png">
**・トレースプロット（バーンイン期間を含む）**
<img width="600" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/8f91a02b-201e-203f-6861-e7a379123c51.png">

**収束判断には**実際に使用するMCMCサンプルを表す**バーンイン期間を含まないトレースプロット**を使用しますが。MCMCサンプルが収束する様子を確認するために、バーンイン期間を含む図もプロットすると便利です。

#### ①全てのパラメータでRhat < 1.1を満たす
Rhatとは、以下の2つの値の比を取った指標で、どのchainでも同様のサンプルが得られたことを判断するために使用します。

1. 同一のチェーン内でのMCMCサンプルの分散の平均値
2. 異なるチェーンも含めた、全てのMCMCサンプルの分散

[こちらの書籍](https://www.kyoritsu-pub.co.jp/bookdetail/9784320112421)では**1.1以下**を収束の判断基準としているため、2-2で表示されているRhatが全パラメータで1.1以下となっている事を確認します。

本例ではRhatはどのパラメータでも1となっているため、条件①を満たしていると判断できます。

#### ②線が一定の範囲で振動し続けていること
[下図のPyMC3ドキュメントの例](https://docs.pymc.io/en/v3/pymc-examples/examples/getting_started.html)が分かりやすいですが、収束している時は線（MCMCサンプル）が一定の範囲で細かく振動し続けますが、収束していない時は偏りのあるランダムウォーク的な（自己相関が大きい）動きをします。
<img width="450" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/fffe8018-0ce7-b046-b123-f887c1eed2aa.png">
[本例でのトレースプロット]()はどのパラメータも線が一定の範囲で細かく振動しているため、条件②を満たしていると判断できます。

#### ③全てのchainで同様の動きをしていること
全てのchainでモデル式や事前分布は同じものを設定しているので、うまく収束していればchainごとにほぼ同じ結果となるはずです。よってトレースプロットにおいて**全てのchain線同士が交り合って同様の動きをしている**ことを確認します。
（参考：[収束していない例](https://m-clark.github.io/bayesian-basics/diagnostics.html)）
<img width="360" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/718068c5-ea6f-cc53-9c79-d47a0f496905.png">
[本例でのトレースプロット]()はどのパラメータも特定のchainで外れた動きは見られないため、条件③を満たしていると判断できます。

※他にも収束を判断する手法の一つとして、[後述の自己相関コレログラム]()や[事後分布ヒストグラム]()が挙げられます

### 3-2. MCMCサンプルの取得
以降の処理では基本的にMCMCサンプルが必要となるため、使用しやすい形で保持しておきます。

以下のように、`rstan::extract()`メソッド（`extract()`というメソッドは他のライブラリにも存在するため、ライブラリ名を付加して使用する）でMCMCサンプルを取得できます。

```r:MCMCサンプルの抽出
# MCMCサンプルの抽出(`permuted=FALSE`でMCMCサンプルの並び順保持)
mcmc_sample_raw <- rstan::extract(mcmc_result, permuted = FALSE)
dim(mcmc_sample_raw)  # MCMCサンプルの要素数（iter-warmup × chains x パラメータ数）
dimnames(mcmc_sample_raw)  # 各々の名称（iterations, chains, parameters）
```

```:実行結果
[1] 1000    4  153
$iterations
NULL

$chains
[1] "chain:1" "chain:2" "chain:3" "chain:4"

$parameters
  [1] "mu"        "sigma"     "pred[1]"   "pred[2]"   "pred[3]"  
  [6] "pred[4]"   "pred[5]"   "pred[6]"   "pred[7]"   "pred[8]"  
 [11] "pred[9]"   "pred[10]"  "pred[11]"  "pred[12]"  "pred[13]" 
  :
[146] "pred[144]" "pred[145]" "pred[146]" "pred[147]" "pred[148]"
[151] "pred[149]" "pred[150]" "lp__"
```

#### ※`permuted`引数について
`rstan::extract()`メソッドには`permuted`という引数がありますが、ここをFALSEにしたときとTRUEにしたときで結果が大きく変わるので、解説します。

`FALSE`の時はMCMCサンプルの並び順を保持し、`TRUE`のときは並び順を保持しない事が最大の差ですが、取得されるデータ構造にも差があります。

後で頻繁に登場するbayesplotライブラリや、サンプルの並び順が必要なトレースプロットでは`permuted=FALSE`のサンプルを使用する必要がありますが、`permuted=TRUE`の方がデータの持ち方がシンプルで扱いやすいので、用途によって使い分ける必要があります。

下表に用途による`permuted`引数の使い分けをまとめました

|permutedの値|データ全体構造|MCMCサンプルの持ち方|パラメータmuのMCMCサンプル取得例|用途|
|---|---|---|---|---|
|**FALSE**|3次元配列に格納されたmatrix|chainごとに列分けして格納|mcmc_sample_raw[,,"mu"]|**bayesplotによる可視化, トレースプロット**|
|**TRUE**|data.frame|全てのchainのサンプルを合体して格納|mcmc_sample$mu|**bayesplotを使用しない事後分布・事後予測分布の算出**|

本記事では以後、違いがわかるよう**以下のように変数名を統一します**

|permutedの値|並び順|MCMCサンプルの変数名|
|---|---|---|
|FALSE|保持|mcmc_sample_raw|
|TRUE|保持しない|mcmc_sample|

#### ※自己相関コレログラムによる収束の確認
MCMCサンプリングがうまく収束しているかを判断する手法として、前述の[Rhatやトレースプロット]()以外にも**「自己相関コレログラム」**が挙げられます。

自己相関とは、「前のデータが大きければ次のデータも大きい」というような、近傍のデータとの相関関係を見るための指標で、MCMCサンプリングにおいては基本的に低い（サンプリングの順番が離れるに従い急速に自己相関が低減する）事が望ましいです。

[参考書籍]()を見る限り、自己相関まできっちり確認している例は少なそうですが、参考までに[後述のbayesplot](https://dastatis.github.io/pdf/StanAdvent2018/bayesplot.html)ライブラリによる自己相関コレログラムのプロット方法を下記します

```r:自己相関コレログラムのプロット
# 自己相関の評価
library(bayesplot)
mcmc_acf_bar(mcmc_sample_raw, pars = c("mu", "sigma"))
```
![スクリーンショット 2022-01-23 21.17.27.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/9ffa508c-8acd-a789-ea83-5094ac88b38f.png)
**右に行くほど棒グラフの高さ（自己相関）が急速に減衰**していることが、**望ましい挙動**と言え、本例ではその条件を満たしていそうです。

### 3-3. 事後分布（信用区間）の可視化
事後分布の可視化には、[bayesplot](https://dastatis.github.io/pdf/StanAdvent2018/bayesplot.html)というライブラリを使用してヒストグラムで描画すると便利です。

```r:bayesplotによる事後分布（信用区間）の可視化
library(bayesplot)
# ヒストグラム描画
mcmc_hist(mcmc_sample_raw, pars = c("mu", "sigma"))
# カーネル密度推定
mcmc_dens(mcmc_sample_raw, pars = c("mu", "sigma"))
# 信用区間
mcmc_intervals(
  mcmc_sample_raw, pars = c("mu", "sigma"),
  prob = 0.95,  # 太い線の範囲（95%信用区間）
  prob_outer = 0.99  # 細い線の範囲（99%信用区間）
)
```
事後分布のヒストグラムは、`mcmc_hist()`関数でプロット出来ます。
<img width="500" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/87ec449a-169f-2115-b213-6022b3f3593a.png">
**事後分布からは、以下の情報**を読み取ることが出来ます。

**A. 収束判断の補助とする**
→収束していない場合複数の峰を持ついびつな形状となる事が多い

**B. パラメータの値の範囲をざっくり把握する**
→上例では、muは3.05付近、sigmaは0.45付近を中心として、どちらもほぼ左右対称に分布していることが分かる

また、`mcmc_dens()`関数で、カーネル密度推定で平滑化した事後分布をプロットできます。
<img width="500" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/24e990ba-718a-b19c-6054-26f334e2d803.png">
さらに、`mcmc_intervals()`関数で、[先ほど求めた信用区間]()をグラフで図示することが出来ます
<img width="500" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/9ae574b8-8aa5-6b4d-c3c5-c28c0aa6118a.png">
スケールが広く見辛いですが、太い線が95%信用区間を、細い線が99%信用区間を表しています。

信用区間と前述のヒストグラムとの関係ですが、パラメータのMCMCサンプルの95%（=ヒストグラムの面積の95%）が含まれる範囲が、95%信用区間となっています。

#### 参考: 信用区間に基づく平均値の検定
信用区間の活用法の一つとして、**[平均値の検定](http://www.aoni.waseda.jp/abek/document/t-test.html)の代用**が挙げられます。

平均値の検定には、一般的にz検定やt検定（信頼区間に基づく検定）が使用されますが、ベイズ統計モデリングにおいても類似した解釈を得ることができます。

例えば上記の例において、**「sepal_lengthの平均は2.9と等しい」**という仮説を判定したい場合、**muの信用区間内に3.0が含まれるか**を見れば良いです。
例えば有意水準を5%とした場合、muの95%信用区間(2.99-3.13)内に2.9が含まれないため、仮説が棄却されて「sepal_lengthの平均は2.9より有意に大きい」と判断できます。
（同様の考え方は[回帰で変数の有効性を判定する際]()にも使用できます）

なお、平均値の検定の代用として使用する場合、[前述の信用区間と信頼区間の解釈の違い]()に注意してください。

|区間推定の名称|95%区間推定の解釈|
|---|---|
|信頼区間(z検定やt検定による平均値の検定)|「100回信頼区間の推定を行うと、95回真の平均が信頼区間内に含まれる」|
|信用区間(ベイズ統計モデリングによる平均値の検定)|「平均が95％の確率で信用区間内に含まれる」|
これらの手法はどちらが正しいというわけではなく、同目的「平均値が想定値に対して有意差を持つか」に対して異なるアプローチ（[頻度主義とベイズ主義](https://ai-trend.jp/basic-study/bayes/basic-2/)）から検証を行なっていると解釈できます。

どちらのアプローチを取るかはケースに応じて判断する必要がありますが、今回のケースでは[多くの先人が言及](https://tjo.hatenablog.com/entry/2016/03/10/190000)されているように、Excelでも簡単に実行できるz検定やt検定（わざわざ手間をかけてStanを使う必要性が低い）で十分かと思います。

### 3-4-1. 事後予測分布のデータとの一致確認
事後予測分布がデータの分布と一致しているかを目視確認し、**モデルの妥当性があるかを定性的に判断**します。

```r:bayesplotによる事後予測分布のデータとの一致確認
# 事後予測分布のMCMCサンプル取得
y_rep <- rstan::extract(mcmc_result)$pred
# 事後予測分布のヒストグラム描画
ppc_hist(y = iris$Sepal.Width,
         yrep = y_rep[1:5,])
```

[事後予測分布のヒストグラム]()
左上に濃色でプロットされている「実際のデータの分布形状」と、それ以外の淡色でプロットされた「事後予測分布」の分布形状が一致していそうなので、定性的にはモデルの妥当性ありと判断できそうです。

~~なお、**ここで求めている事後予測分布のヒストグラム**1つ1つは、[前述の予測区間の解説]()において「MCMCサンプルから1サンプルのみ抜き出した唯一のパラメータ」を使用している状態です。サンプル数1（[前述の近似式]()においてiを1個しか選んでいない状態）のため、事後予測分布を求めるための積分を近似できているとは言えず、**精度の低いざっくり確認**と見なすのが適切です。~~
→extract時に`permuted=FALSE`を指定しておらずサンプル取得がランダムなので、「iを1個しか選んでいない状態」にはなっていなさそうです。

いずれにせよ上記は事後予測分布のMCMCサンプルを全て使用していない（4000個中150個のみ使用）状態なので、**予測区間を求める際は、全てのサンプルを使用してより高精度な事後予測分布の推定を行います（後述）**

### 3-4-2. 予測区間の算出と事後予測分布の可視化
前節で述べたように、全てのサンプルを使用して高精度な事後予測分布を推定し、そこから予測区間を算出します。
（[前述のように]()今回のケースでは事後予測分布をN回繰り返して求めていますが、基本的にはどのイテレーションでも同じ値を求める処理となっているため、今回は1回目の結果のみをプロットします）

```r:bayesplotによる予測区間と事後予測分布の可視化
# 予測区間を可視化
mcmc_intervals(
  mcmc_sample_raw,  # MCMCサンプル（`permuted=FALSE`のサンプル）
  pars = c("pred[1]"), #正規表現で描画対象のパラメータを指定
  prob = 0.95,  # 太い線の範囲(95%予測区間)
  prob_outer = 0.99,  # 細い線の範囲(99%予測区間)
)

# 予測区間をヒストグラムで可視化
mcmc_areas(
  mcmc_sample_raw,  # MCMCサンプル（`permuted=FALSE`のサンプル）
  pars = c("pred[1]"), #正規表現で描画対象のパラメータを指定
  prob = 0.95,  # 太い線の範囲(95%予測区間)
  prob_outer = 0.99,  # 細い線の範囲(99%予測区間)
)
```
予測区間は、`mcmc_intervals()`関数でプロット出来ます。
![スクリーンショット 2022-01-24 0.44.37.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/26459607-c8db-41a8-7b5a-8551784cea0f.png)
太い線が95%予測区間を、細い線が99%予測区間を表しています。
ここで求めた[予測区間は後述の異常検知でも使用します]()

事後予測分布のヒストグラムは、`mcmc_areas()`関数でプロット出来ます。
![スクリーンショット 2022-01-24 0.45.10.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/1cabf993-4a3c-3b1e-9953-a5c707261412.png)
塗りつぶし部分が95%予測区間を、線が存在する部分が99%予測区間を表しており、事後予測分布のMCMCサンプルの95%（=ヒストグラムの面積の95%）が含まれる範囲が95%予測区間となっていることが、図を見ると分かりやすいかと思います

### 3-5. 異常検知
先ほど求めた予測区間を使用することで、**異常検知**を実施することも出来ます。

○%予測区間は「データの◯%が含まれる範囲」を表すため、○の値に1に近い値（例:0.95, 0.99, 0.999など）を使用する事で、「データの大半が含まれる範囲」と解釈する事ができます。
逆に言うと、**「予測区間の外側のデータ = 通常とは異なるデータ = 何らかの異常がある可能性の高いデータ」**とみなすことができ、予測区間の外にあるかどうかで**異常検知**を実現する事ができます。

例えば今回の例において95%予測区間の外側を異常とみなす異常検知を、以下のように実装します。

```r:予測区間に基づく異常検知と結果の可視化
# 異常検知の閾値（指定した予測区間の外側なら異常とみなす）
P_THRESHOLD = 0.95
lower = (1 - P_THRESHOLD)/2  # 下限
upper = 1 - lower  # 上限
# 事後予測分布のMCMCサンプルをベクトル化（chainsを合体）
mcmc_pred_1 = as.vector(mcmc_sample_raw[,,"pred[1]"])
# 予測区間の上下限を取得
threshold = quantile(mcmc_pred_1, probs=c(lower, 0.5, upper))
threshold
# 予測区間の外側のデータ（異常値）を判定
outlier = sepal_width < threshold[1] | sepal_width > threshold[3]
# プロット用のDataFrame
df_outlier = data.frame(x=sepal_width, y=1, outlier=outlier) # 異常判定
df_pred_range = data.frame(x=c(threshold[1], threshold[3]), y=c(0,0)) # 予測区間
# 事後予測分布と外れ値データをプロット
mcmc_areas(
  mcmc_sample_raw,  # MCMCサンプル（`permuted=FALSE`のサンプル）
  pars = c("pred[1]"), #正規表現で描画対象のパラメータを指定
  prob = 0.95,  # 太い線の範囲(95%予測区間)
  prob_outer = 0.99,  # 細い線の範囲(99%予測区間)
) + 
  geom_point(data=df_outlier, aes(x=x, y=y, color=outlier), size=3) +
  scale_colour_manual(values = c("blue", "red"))
```
![スクリーンショット 2022-01-24 1.09.28.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/983aeec6-dc82-8d23-255c-1ade27e8edc0.png)
青い丸が正常と判定されたデータ（予測区間内のデータ）を、赤い丸が異常と判定されたデータ（予測区間外のデータ）を表しています。

このような異常検知は正常・異常のラベル分けなしで実行できる（教師なし学習に近い）ため、
工場の品質管理のような**「異常データを多く取得することが難しいケース」**において多用される手法であり、ホテリング理論やマハラノビスタグチ法、Autoencoderなどと共に、ベイズ統計モデリングもその実装例としてよく利用されています。
（[参考書籍](https://www.coronasha.co.jp/np/isbn/9784339024913/)）

<br>

# ユースケース2. 単回帰モデル
先ほどの[iris（アヤメ）データセット](https://note.nkmk.me/python-scikit-learn-svm-iris-dataset/)には、応答変数として使用した`sepal_width`(がくの幅)以外にも、`sepal_length`(がくの長さ)、`petal_width`(花弁の幅)、`petal_length`(花弁の長さ)という変数を持ちます
![9cede6e3-0932-430a-a17e-d30025eb2b02.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/27bc8bfb-0dd4-b5e2-e506-8989a2c5e081.png)
これらの変数間には相関関係があるため、例えば`petal_length`を入力データ(説明変数)として与えることで、`petal_width`をより高精度で求める(予測区間の幅を狭める)ことが出来ます。

このように**説明変数との関係を利用して応答変数の値を予測することを回帰**と呼び、特に**説明変数が1個**の場合を**単回帰**と呼びます。

今回は`petal_length`のみを説明変数,`petal_width`を応答変数として、単回帰モデルの構築を実施します。


## 手順1. 確率モデルの構築
**説明変数**`petal_length `と**応答変数**`petal_width `との**関係式**
すなわち

**・線形予測子**
**・リンク関数**
**・確率分布**

を確定させます。

関係式を判断するための前準備として、まずは散布図による可視化を行います

```r:散布図による可視化
# データ読込（irisデータセットのpetal_lengthとpetal_width）
df_iris <- data.frame(
  petal_width = iris$Petal.Width,
  petal_length = iris$Petal.Length
)
# 散布図描画
library(ggplot2)
ggplot(df_iris, aes(x = petal_length, y = petal_width)) +
  geom_point() +
  labs(title ="petal_length and petal_width")
```

### 線形予測子
petal_lengthに対してpetal_widthがほぼ線形に増加しているため、1次式を線形予測子として使用する事ができそうです。

なお、2次式、3次式と**次数を増やす**とデータに対する当てはまりが向上する事も多いですが、[機械学習の場合と同様に](https://qiita.com/c60evaporator/items/ca7eb70e1508d2ba5359#c-汎化性能の向上正則化)今あるデータに過剰に適合した**過学習**状態となりやすいため、明確な根拠がない場合は安易な次数の増加は避けるべきです。

### リンク関数
リンク関数に関しては、散布図を見ても非線形な変換は不要と思われるため、リンク関数には入力をそのまま返す**恒等関数**を使用します。

このような**正規分布＋恒等関数**の組み合わせはこの先のユースケースでも**基本となる**ため、覚えておいていただければと思います。

### 確率分布
回帰問題においてはユースケース1のようなシンプルなヒストグラムを描く事ができないため、分布形状を判断する難易度が格段に上がります。

このような場合、よほど分布に偏りがあったり、明確なドメイン知識がない限りは**正規分布を採用する事が無難**です（少ないデータで分布形状を見分ける事は困難なため）
今回の場合も散布図を見る限り大きな偏りはなさそうなので、正規分布を採用します。

なお[詳細は後述しますが]()、モデル作成後に「応答変数の真値 - モデルの予測値」、すなわちモデルの誤差の分布形状を見ることで、選択した確率分布に妥当性があるかを後から判断することができます。

### 完成したモデル式
[前述のように]()、
・平均パラメータmuが先ほど定めた線形予測子とリンク関数に従う
・応答変数が平均mu、標準偏差sigmaの正規分布（先ほど定めた確率分布）に従う
という条件に基づくと、以下のように立式できます

```math
\mu[n]=Intercept+\beta x[n]\\
y[n] \sim Normal(\mu[n],\sigma)
```

```math
\left\{\begin{array}{ll}
n:データ数\\
x:説明変数petal.length\\
y:応答変数petal.width\\
Intercept:切片\\
\beta:説明変数petal.lengthの係数\\
Normal(y \mid \mu,\sigma):平均\mu,標準偏差\sigmaの\\正規分布における確率密度関数\\
\end{array}\right.
```
このモデル式をコードに落とし込み、MCMCによるモデル化を実行します

## 手順2. MCMCでパラメータの事後分布算出
Stanを使い、MCMCでパラメータの事後分布を求めていきます。

### 2-1. MCMC実行
[ユースケース1の場合]()と同様に、StanファイルとRファイルを記述してMCMCを実行します。

#### Stanファイル
手順1で決めたモデルに基づき、

・データの定義
・パラメータ
・中間パラメータ（非独立なパラメータ）
・モデル式（場合によっては事前分布も）
・予測分布の算出式

をブロックに分け、以下のように記載します。

```kotlin:usecase2_simple_regression.stan
// dataブロック（データの定義）
data {
  int N;       //データ数
  vector[N] petal_width;//花弁の幅(応答変数)
  vector[N] petal_length;//花弁の長さ(説明変数)
  
  int N_pred;  //予測の横軸要素数
  vector[N_pred] petal_length_pred;  //予測の横軸となる説明変数のベクトル
}

// parametersブロック（パラメータの定義）
parameters {
  real Intercept;//切片
  real beta; //係数
  real<lower=0> sigma;//標準偏差
}

// transformed parametersブロック（中間パラメータの計算式を記述）
transformed parameters {
  //平均mu = intercept + beta*petal_length
  vector[N] mu = Intercept + beta*petal_length;
}

// modelブロック（モデル式を記述）
model {
  //平均mu、標準偏差sigmaの正規分布
  petal_width ~ normal(mu, sigma);
}

// generated quantitiesブロック（事後予測分布を記述）
generated quantities {
  vector[N_pred] mu_pred; // 期待値muの事後分布
  vector[N_pred] petal_width_pred; // 応答変数の事後分布（事後予測分布）
  // 事後予測分布を得る
  for (i in 1:N_pred){
    mu_pred[i] = Intercept + beta*petal_length_pred[i];
    petal_width_pred[i] = normal_rng(mu_pred[i], sigma);
  }
}
```
ブロック毎に解説します。

##### ・dataブロック
dataブロックには、入力するデータの定義を記載します。
本ケースでは、以下が該当します。

・データ数
・使用する変数（説明変数petal_length＋応答変数petal_width）
・予測区間算出用の横軸データ（横軸要素数N_pred＋横軸用の説明変数ベクトルpetal_length_pred）

```kotlin
data {
  int N;       //データ数
  vector[N] petal_width;//花弁の幅(応答変数)
  vector[N] petal_length;//花弁の長さ(説明変数)
  
  int N_pred;  //予測の横軸要素数
  vector[N_pred] petal_length_pred;  //予測の横軸となる説明変数のベクトル
}
```
**[ユースケース1（回帰要素を持たない場合）]()の場合との差**は、**「予測区間算出用の横軸データ」**の部分です。

[後述しますが]()、下図のように回帰問題で予測区間（および平均muの信用区間）を可視化するためには、横軸となる説明変数の範囲をベクトルで指定する必要があります。
<img width="400" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/2a752d64-798e-6315-67dd-e6d6e74acf63.png">
Stanにおいて説明変数の範囲を指定するためには、「範囲を表すベクトル」+「ベクトルの要素数」を指定する必要があります。
今回の例ではそれぞれ`petal_length_pred `と`N_pred`が該当します。

※説明変数が複数ある場合は、[ユースケース3:重回帰]()で解説します。

##### ・parametersブロック
モデル式に含まれる、推定したいパラメータ

・Intercept（切片）
・beta（説明変数petal_lengthの係数）
・sigma（正規分布の標準偏差）

を記載します。

```kotlin
parameters {
  real Intercept;//切片
  real beta; //係数
  real<lower=0> sigma;//標準偏差
}
```

##### ・transformed parametersブロック
[ユースケース1]()には存在しなかったブロックですが、他のパラメータからの演算で求められる中間的なパラメータ（非独立なパラメータ）を記載します。
本ケースでは、平均`mu`が該当します。

```kotlin
transformed parameters {
  //平均mu = intercept + beta*petal_length
  vector[N] mu = Intercept + beta*petal_length;
}
```
前述のように、パラメータ`mu`は

```math
\mu[n]=Intercept+\beta x[n]\\
```
というように他のパラメータ`Intercept`および`beta`から求められる非独立なパラメータのため、parametersブロックではなくtransformed parametersブロックに記載する必要があります。

この`mu`のような中間的なパラメータは、[後述のmodelブロック]()にまとめて

```kotlin:transformed　parametersブロックを使用しない場合のmodelブロック記載例
model {
  //平均intercept + beta*petal_length、標準偏差sigmaの正規分布
  vector[N] mu = Intercept + beta*petal_length;
  petal_width ~ normal(mu, sigma);
}
```
のように記載することで、**transformed parametersブロックを使用しなくとも演算自体は可能**ですが、
transformed parametersブロックを使用すると全入力データN個に対してそれぞれmuの事後分布が得られ、[後述の誤差計算]()等において便利なので、本ケースではこの方法を使用することとします。

##### ・modelブロック
[前述のモデル式]()をStanコードに落とし込みます。muの計算式（線形予測子＋リンク関数）はtransformed　parametersブロックに記載済なので、ここには確率分布の式のみを記載します。

```kotlin
model {
  //平均mu、標準偏差sigmaの正規分布
  petal_width ~ normal(mu, sigma);
}
```
※[ベクトル化記法]()で記述しています

##### ・generated quantitiesブロック
generated quantitiesブロックには、MCMCによるパラメータ推定から直接求められない

・平均muの事後分布（muの信用区間の可視化に使用）
・事後予測分布（予測区間の可視化に使用）

の計算方法を記述します。

```kotlin
generated quantities {
  vector[N_pred] mu_pred; // 平均muの事後分布
  vector[N_pred] petal_width_pred; // 応答変数の事後分布（事後予測分布）
  // 事後予測分布を得る
  for (i in 1:N_pred){
    mu_pred[i] = Intercept + beta*petal_length_pred[i];
    petal_width_pred[i] = normal_rng(mu_pred[i], sigma);
  }
}
```
今回のように回帰的要素（線形予測子）を含む場合、事後予測分布の算出アルゴリズムがやや複雑となるため、詳細は[後述の予測区間の算出]()の項で解説します。

<br>

#### Rファイル
Rファイル側には、以下の内容を記載します

・パッケージ読込(RStan)
・計算高速化のための記述(コンパイルファイルの都度保存＋計算並列化)
・データをStanに読み込める形式(list形式)にまとめる
・MCMC実行(`stan()`メソッド)

```r:StanでMCMCによりパラメータの事後分布算出
# パッケージ読込
library(rstan)

# 計算高速化
rstan_options(auto_write=TRUE)  # コンパイルファイルの保存
options(mc.cores = parallel::detectCores())  # 計算並列化

# 事後予測分布の横軸となる説明変数のベクトル
PETAL_LENGTH_PRED <- seq(1, 7, by = 0.5)

# list形式にデータをまとめる（stanファイルのdataブロックと名称を揃える）
N <- nrow(iris)  # データ数
data_list <- list(
  N = N,
  petal_width = df_iris$petal_width,
  petal_length = df_iris$petal_length,
  N_pred = length(PETAL_LENGTH_PRED),
  petal_length_pred = PETAL_LENGTH_PRED
  )
data_list

# MCMC実行
mcmc_result <- stan(
  file = "./stan/usecase2_simple_regression.stan", # stanファイルのパス
  data = data_list, # 対象データ
  seed = 1,         # 乱数シード
  chains = 4,       # 初期値の個数（全初期値で近い結果となれば収束と判断）
  iter = 2000,      # サンプリングの繰り返し数
  warmup = 1000,    # バーンイン期間（収束前と見なして捨てるサンプル数）
  thin = 1          # 間引き数（1なら間引きなし）
)
```
**[ユースケース1（回帰要素を持たない場合）]()との差**として、**「事後予測分布の横軸となる説明変数のベクトル」**の指定が挙げられます。指定方法は[前述のStanファイルの`data`ブロック]()を参照ください。

上記コードを実行し、完了するまで待ちます（PCスペックにより変わりますが、数10秒〜数分掛かるかと思います）

### 2-2. MCMC結果の概要を確認
`print()`関数で、MCMC結果の概要（各パラメータの推定結果）を確認します。

```r:MCMC結果の概要を表示
options(max.print=2000) # printの表示上限を増やす(lp__が表示されるように)
print(
  mcmc_result,                  # MCMCサンプルの結果
  probs = c(0.025, 0.5, 0.975)  # 中央値と95%信用区間を出力
)
```

```:結果
                       mean se_mean   sd   0.5%   2.5%    50%  97.5%  99.5% n_eff Rhat
Intercept             -0.36    0.00 0.04  -0.46  -0.44  -0.36  -0.28  -0.26  1824    1
beta                   0.42    0.00 0.01   0.39   0.40   0.42   0.43   0.44  1875    1
sigma                  0.21    0.00 0.01   0.18   0.19   0.21   0.23   0.24  2078    1
mu[1]                  0.22    0.00 0.03   0.15   0.16   0.22   0.27   0.30  1949    1
  :
mu[150]                1.76    0.00 0.02   1.70   1.71   1.76   1.80   1.81  3855    1
mu_pred[1]             0.05    0.00 0.03  -0.03  -0.01   0.05   0.12   0.14  1892    1
  :
mu_pred[13]            2.55    0.00 0.04   2.46   2.48   2.55   2.62   2.64  2559    1
petal_width_pred[1]    0.06    0.00 0.21  -0.47  -0.35   0.06   0.47   0.62  4058    1
  :
petal_width_pred[13]   2.55    0.00 0.21   1.98   2.13   2.54   2.96   3.08  3781    1
lp__                 159.52    0.03 1.24 154.35 156.36 159.83 160.93 161.01  1589    1
```
表示された結果の**列名**は、以下のように解釈します

|列名|内容（特に重要な列は太字）|
|---|---|
|一番左の列|推定したパラメータの名称|
|mean|パラメータ事後分布の平均|
|se_mean|パラメータ事後分布の標準誤差|
|sd|パラメータ事後分布の標準偏差|
|0.5%|**99%信用区間の下限**|
|2.5%|**95%信用区間の下限**|
|50%|事後分布のメディアン|
|97.5%|**95%信用区間の上限**|
|99.5%|**99%信用区間の上限**|
|n_eff|実効MCMCサンプル数([こちらの書籍](https://www.kyoritsu-pub.co.jp/bookdetail/9784320112421)では100以上推奨)|
|Rhat|**収束判断のための指標**([こちらの書籍](https://www.kyoritsu-pub.co.jp/bookdetail/9784320112421)では1.1以下推奨)|

表示された結果の**行名(推定したパラメータ名)**は、以下のように解釈します

|パラメータ名|内容（特に重要な列は太字）|
|---|---|
|Intercept|切片|
|beta|説明変数petal.lengthの係数|
|sigma|標準偏差パラメータsigma|
|mu[i]|平均パラメータmuの事後分布<br>(全ての入力データN個に対して算出)|
|mu_pred[i]|平均パラメータmuの事後分布<br>([前述の横軸指定した説明変数ベクトル]()N_pred個に対して算出)|
|petal_width_pred[i]|事後予測分布<br>([前述の横軸指定した説明変数ベクトル]()N_pred個に対して算出)|
|lp__|対数事後確率([前述]())|
上記パラメータのうち、**MCMCで直接求まったパラメータ**はStanファイルの**`parameters`ブロックに記載された**Intercept, beta, sigmaのみです

[後述の可視化]()に使用するmuの事後分布`mu_pred[i]`および応答変数の事後予測分布`petal_width_pred[i]`は**MCMCで直接求まらない**ため、Stanファイルの**`generated quantities`ブロックに記載した計算式に基づき算出**されます。[算出アルゴリズムの詳細については後述します]()

各入力データに対応するmuの事後分布`mu[i]`も同様にMCMCで直接求まらないため、`transformed parameters`ブロックの計算式に基づき算出されます。

## 手順3. モデルの評価
MCMCによって構成されたモデルを各種手法で評価し、モデルの妥当性を評価したり、各種解釈を得ます。
### 3-1. トレースプロットによる収束の確認
[ユースケース1]()と同様に以下の条件を満たしているかどうかを判定し、収束を確認します。

①全てのパラメータで[前述の]()**Rhat < 1.1**を満たす
②トレースプロットが**一定の範囲で振動**し続けていること
③トレースプロットが**全てのchainで同様の動き**をしていること

```r:トレースプロットの可視化
# トレースプロット（バーンイン期間を含まない）
traceplot(mcmc_result, pars = c("mu", "sigma", "lp__")) +
  labs(title="Without warmup")
# トレースプロット（バーンイン期間を含む）
traceplot(mcmc_result, inc_warmup=T, pars = c("mu", "sigma", "lp__")) +
  labs(title="Including warmup")
```
**・トレースプロット（バーンイン期間を含まない）**
<img width="600" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/e8dbd979-e7ec-0eb9-ba73-ae4c605d1e8f.png">
**・トレースプロット（バーンイン期間を含む）**
<img width="600" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/2b2b1690-414f-2e61-a4b8-bda04d2feec2.png">
**収束判断には**実際に使用するMCMCサンプルを表す**バーンイン期間を含まないトレースプロット**を使用します。

#### ①全てのパラメータでRhat < 1.1を満たす
2-2で表示されているRhatが全パラメータで1.1以下となっているため、条件①を満たしていると判断できます。

#### ②線が一定の範囲で振動し続けていること
[本例でのトレースプロット]()はどのパラメータも線が一定の範囲で細かく振動しているため、条件②を満たしていると判断できます。

#### ③全てのchainで同様の動きをしていること
[本例でのトレースプロット]()はどのパラメータも特定のchainで外れた動きは見られないため、条件③を満たしていると判断できます。

### 3-2. MCMCサンプルの取得
以降の処理では基本的にMCMCサンプルが必要となるため、使用しやすい形で保持しておきます。

以下のように、`rstan::extract()`メソッド（`extract()`というメソッドは他のライブラリにも存在するため、ライブラリ名を付加して使用する）でMCMCサンプルを取得できます。

```r:MCMCサンプルの抽出
# MCMCサンプルの抽出(`permuted=FALSE`でMCMCサンプルの並び順保持)
mcmc_sample_raw <- rstan::extract(mcmc_result, permuted = FALSE)
dim(mcmc_sample_raw)  # MCMCサンプルの要素数（iter-warmup × chains x パラメータ数）
dimnames(mcmc_sample_raw)  # 各々の名称（iterations, chains, parameters）
```

```:実行結果
[1] 1000    4   30
$iterations
NULL

$chains
[1] "chain:1" "chain:2" "chain:3" "chain:4"

$parameters
  [1] "Intercept"            "beta"                 "sigma"               
  [4] "mu[1]"                "mu[2]"                "mu[3]"               
   :     :
[151] "mu[148]"              "mu[149]"              "mu[150]"             
[154] "mu_pred[1]"           "mu_pred[2]"           "mu_pred[3]"          
[157] "mu_pred[4]"           "mu_pred[5]"           "mu_pred[6]"          
[160] "mu_pred[7]"           "mu_pred[8]"           "mu_pred[9]"          
[163] "mu_pred[10]"          "mu_pred[11]"          "mu_pred[12]"         
[166] "mu_pred[13]"          "petal_width_pred[1]"  "petal_width_pred[2]" 
[169] "petal_width_pred[3]"  "petal_width_pred[4]"  "petal_width_pred[5]" 
[172] "petal_width_pred[6]"  "petal_width_pred[7]"  "petal_width_pred[8]" 
[175] "petal_width_pred[9]"  "petal_width_pred[10]" "petal_width_pred[11]"
[178] "petal_width_pred[12]" "petal_width_pred[13]" "lp__"   
```

### 3-3-1. 事後分布（信用区間）の可視化
[ユースケース1と同様]()、[bayesplot](https://dastatis.github.io/pdf/StanAdvent2018/bayesplot.html)を使用して各パラメータの事後分布を可視化します。

```r:bayesplotによる事後分布（信用区間）の可視化
library(bayesplot)
# ヒストグラム描画
mcmc_hist(mcmc_sample_raw, pars = c("Intercept", "beta", "sigma"))
# カーネル密度推定
mcmc_dens(mcmc_sample_raw, pars = c("Intercept", "beta", "sigma"))
# 信用区間
mcmc_intervals(
  mcmc_sample_raw, pars = c("Intercept", "beta", "sigma"),
  prob = 0.95,  # 太い線の範囲（95%信用区間）
  prob_outer = 0.99  # 細い線の範囲（99%信用区間）
)
```
**・事後分布のヒストグラム**
<img width="500" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/40b38b4e-e60f-9e60-2100-9817927410cf.png">
**・事後分布のカーネル密度推定**
<img width="500" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/82e58294-bfb0-c36e-fed1-3bd2e8c75b5d.png">
**・95%および99%信用区間**
<img width="500" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/8a39f50c-5072-2cb1-cbb2-c08dc03b040d.png">
太い線が95%信用区間を、細い線が99%信用区間を表しています。

**上記事後分布から、以下の情報**を読み取ることが出来ます。

**A. 収束判断の補助とする**
→複数の峰を持ついびつな形状となっていないため、収束したと判断できそう

**B. パラメータの値の範囲をざっくり把握する**
→上例では、
・切片Interceptは-0.36付近
・petal_lengthの係数係数betaは0.42付近
・標準偏差sigmaは0.21付近
を中心として、どれもほぼ左右対称に分布していることが分かる

### 3-3-2. 平均muの信用区間の可視化
Interceptやpetal_lengthの信用区間はあくまで個々のパラメータの存在範囲を表す指標であり、実際のデータとの関係性が直感的に理解し辛いです。

単回帰においては、散布図上に**平均muの信用区間**をプロットすると、**直感的な理解がしやすく**なります。

muの事後分布は[前述のStanコードの`generated quantities`ブロック]()で算出済（[算出アルゴリズムは3-4で後述]()）のため、ここから以下のコードでmuの信用区間を求め散布図上に可視化します。

```r:平均muの信用区間を散布図上に表示
# MCMCサンプル取得(`permuted=TRUE`を指定)
mcmc_sample <- rstan::extract(mcmc_result, permuted = TRUE)

# muの95%信用区間と99%信用区間を取得
qua_mu <- apply(mcmc_sample$mu_pred,
                2,
                quantile,
                probs=c(0.005, 0.025, 0.50, 0.975, 0.995))
df_qua_mu <- data.frame(
  petal_length=PETAL_LENGTH_PRED,
  t(qua_mu),
  check.names = FALSE
  )
# muの95%信用区間と99%信用区間をプロット
ggplot() +
  theme_bw(base_size=18) +
  geom_ribbon(data=df_qua_mu, aes(x=petal_length, ymin=`0.5%`, ymax=`99.5%`),
              fill='black', alpha=1/6) +
  geom_ribbon(data=df_qua_mu, aes(x=petal_length, ymin=`2.5%`, ymax=`97.5%`),
              fill='black', alpha=2/6) +
  geom_line(data=df_qua_mu, aes(x=petal_length, y=`50%`), size=1) +
  geom_point(data=df_iris, aes(x=petal_length, y=petal_width)) +
  labs(y='petal_width', title ='Credible interval of `mu`')
```
**・muの信用区間可視化結果**
![000009.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/3481c8dd-c2dd-d9a8-43a0-8e5bcb6fd6cf.png)
濃い灰色で塗り潰された部分が平均muの95%信用区間を、薄い灰色で塗りつぶされた部分が99%信用区間を表しています。

**説明変数**(petal_length)の**値に応じて応答変数**(petal_width)の**平均値がどのように変化するか**が分かるため、モデルの直感的な理解が深まるかと思います。

### 3-3-3. 誤差計算と確率分布の妥当性確認
[手順1で述べたように]()、モデル作成後に「応答変数の真値 - モデルの予測値」、すなわち**モデル誤差の分布を見る**ことで、手順1で**選択した確率分布に妥当性があるかを判断**することができます。

ここで問題となるのが、**何をもって「モデルの予測値」とするか**です。
これには明確な正解はなく、

|項目|選択肢|
|---|---|
|対象とする事後分布|「事後予測分布」or「平均muの事後分布」|
|点推定の方法|「平均値」or「中央値(50%点)」<br>or「MAP推定値(事後分布が最大となる点)」|

など、モデルの**予測値として多くの定義を使用することができます。**
**本記事では**[こちらの書籍](https://www.kyoritsu-pub.co.jp/bookdetail/9784320112421)の方法に則り、**「平均muのMAP推定値」**を**予測値として使用**します。

こうして求めた予測値を使い、
A.「誤差（実測値-予測値）」の分布
B.手順1で選択した確率分布（標準偏差sigmaの正規分布）
を比較し、一致していれば選択した確率分布の妥当性があると判断できます

```r:「誤差分布」と「選択した確率分布」を比較プロット
# MAP推定用関数
map <- function(z){
  density(z)$x[which.max(density(z)$y)] 
}

# 平均muのMAP推定（予測値として使用）
mu_map <- apply(mcmc_sample$mu, 2, map)
# 誤差（実測値-予測値）
noise_map <- df_iris$petal_width - mu_map
df_noise_map <- data.frame(noise_map=noise_map)

# 標準偏差sigmaのMAP推定
sigma_map <- map(mcmc_sample$sigma)

# 誤差分布と標準偏差sigmaの正規分布との比較
ggplot(data=df_noise_map, aes(x=noise_map)) +
  theme_bw(base_size=18) +
  geom_histogram(bins=20, aes(y=..density..),
                 color='black', fill='white') +
  geom_density(alpha=0.5, color='black', fill='gray50') +
  stat_function(fun=function(x) dnorm(x, mean=0, sd=sigma_map),
                linetype='dashed', color='red')
```
※平均muのMCMCサンプル（mcmc_sample$mu）は、[前述のtransformed parametersブロック]()で求めた`mu[i]`を使用しています
※標準偏差sigmaにはMAP推定値を使用しています
※MAP推定値にはカーネル推定値の最大値を使用しています

**・プロット結果**
![00001f.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/00192312-6d57-903f-a0dd-f054718190e9.png)
上の図は

灰色の分布： A.「誤差（実測値-予測値）」の分布
赤点線の分布： B.手順1で選択した確率分布（標準偏差sigmaの正規分布）

を表しており、**AとBがほぼ重なっている**ことから、**選択した確率分布(正規分布)の妥当性あり**と判断できます。

※ヒストグラムは「A.誤差」のヒストグラムを表しています

### 3-3-4. 予測値-実測値プロット
[機械学習でよく使用される](https://qiita.com/c60evaporator/items/c930c822b527f62796ee#ユースケース2の解決策予測値vs実測値プロット)**予測値-実測値プロット**ですが、ベイズ統計モデリングにおいても精度を確認する上で有効なツールとして使用できます

```r:予測値-実測値プロット
# 予測値と実測値をDataFrameに格納
df_pred_true <- data.frame(
  pred=mu_map,  # 予測値(muのMAP推定値)
  true=df_iris$petal_width  # 実測値(データの応答変数)
)
# 予測値-実測値プロット
ggplot(data=df_pred_true, aes(x=true, y=pred)) +
  geom_point()
```
![predtrue.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/2e2267a2-68dd-8854-88bc-9733ecc81446.png)
「予測値=実測値」の斜めの線周辺にデータが集中しており、定性的にはある程度の予測性能が出ている事がわかります

ここで使用した予測値と実測値を使用してRMSEやMAE等の定量的な指標を算出し、機械学習と予測性能を比較する事もできます（[前述のように]()機械学習とはコンセプトが異なるため、単純な比較は手放しには推奨できませんが…）


### 3-4. 予測区間の算出と可視化
ユースケース1の時と同様に、予測区間は事後予測分布から算出しますが、今回のように**回帰的要素（線形予測子）を含む場合、事後予測分布の算出に一手間加える必要があります**。
まずはその理論について解説します。

#### 解説: 線形予測子を含むモデルの事後予測分布

[前述のように]()、正規分布モデルにおいてパラメータμのMCMCサンプル`μ[i]`とパラメータσのMCMCサンプル`σ[i]`が求まっていれば、事後予測分布は上記パラメータの正規分布に従う乱数サンプリングを新たに行う事で、以下のように算出できます

```math
\sum_{i=1}^{NSample}Normal.Rand(y \mid \mu[i],\sigma[i])
```
※ $Normal.Rand(y \mid \mu[i],\sigma[i])$は、「平均μ[i], 標準偏差σ[i]の正規分布に従う乱数」を表す

一方で本モデルのMCMCでサンプリングしたパラメータはa, b, σのみであり、上記事後予測分布の算出に必要な**μのMCMCサンプル`μ[i]`は現時点では得られていません。**

そこで線形予測子の式$\mu=ax+b$に基づき、**適当な説明変数x（[前述の「事後予測分布の横軸となる説明変数のベクトル」]()に相当）を外部から与える**ことで、aとbのMCMCサンプル`a[i]`および`b[i]`から

$\mu[i]=a[i]x+b[i]$

としてμのMCMCサンプル`μ[i]`を算出可能です。

これにより事後予測分布算出に必要なパラメータ`μ[i]`と`σ[i]`が出揃うので、前述の乱数生成に基づき事後予測分布を求めることができます。

#### 解説: Stanファイルにおける線形予測子を含むモデルの事後予測分布算出
[前述のStanファイル]()における`generated quantities`ブロックで、上記の`μ[i]`および事後予測分布の算出式を記述しています。

```kotlin
generated quantities {
  vector[N_pred] mu_pred; // 平均muの事後分布
  vector[N_pred] petal_width_pred; // 応答変数の事後分布（事後予測分布）
  // 事後予測分布を得る
  for (i in 1:N_pred){
    mu_pred[i] = Intercept + beta*petal_length_pred[i];
    petal_width_pred[i] = normal_rng(mu_pred[i], sigma);
  }
}
```
上記コードの`mu_pred[i] = Intercept + beta*petal_length_pred[I]`の部分が**平均muの事後分布(のMCMCサンプル)`μ[i]`の算出式**を表しており、
・算出済のMCMCサンプル（Intercept, beta）
・外部から与えた適当な説明変数（petal_length_pred）
・線形予測子の式
に基づいて`μ[i]`を求めていることが分かります。

`petal_width_pred[i] = normal_rng(mu_pred[i], sigma)`の部分が**事後予測分布(のMCMCサンプル)`petal_width_pred`の算出式**を表しており、
・平均muのMCMCサンプル`μ[i]`
・標準偏差sigmaのMCMCサンプル`σ[i]`
に基づいて`petal_width_pred`を求めていることが分かります。

#### 予測区間の可視化
上記で算出した事後予測分布(応答変数petal_widthの事後分布)事後分布はMCMCサンプル`petal_width_pred`として得られているため、ここから以下のコードで予測区間を求め、散布図上に可視化します。

```r:予測区間を散布図上に表示
# 95%予測区間と99%予測区間を取得
qua_petal_width <- apply(mcmc_sample$petal_width_pred,
                         2,
                         quantile,
                         probs=c(0.005, 0.025, 0.50, 0.975, 0.995))
df_qua_petal_width <- data.frame(
  petal_length=PETAL_LENGTH_PRED,
  t(qua_petal_width),
  check.names = FALSE
  )
# 95%予測区間と99%予測区間をプロット
ggplot() +  
  theme_bw(base_size=18) +
  geom_ribbon(data=df_qua_petal_width,
              aes(x=petal_length, ymin=`0.5%`, ymax=`99.5%`),
              fill='black',
              alpha=1/6) +
  geom_ribbon(data=df_qua_petal_width,
              aes(x=petal_length, ymin=`2.5%`, ymax=`97.5%`),
              fill='black',
              alpha=2/6) +
  geom_line(data=df_qua_petal_width, aes(x=petal_length, y=`50%`), size=1) +
  geom_point(data=df_iris, aes(x=petal_length, y=petal_width)) +
  labs(y='petal_width', title='Prediction interval')
```
![00000f.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/3ab09cca-780d-25d2-b194-48bfd681780d.png)
濃い灰色で塗り潰された部分が95%予測区間を、薄い灰色で塗りつぶされた部分が99%予測区間を表しています。

**[前述のように]()予測区間は様々な用途に使用できる**ので、この図をプロットする事で、各用途に使用できるか否かの判断や、データの解釈に使用することができます。

### 3-5: 異常検知
予測区間の主用途の一つである**異常検知**を、本ケースにおいて実装してみます。

今回は、「99%予測区間の外側であれば異常である」という条件に基づき、異常検知の実行と、その結果を予測区間と合わせて可視化します。

```r:異常検知と結果の可視化
# 異常検知の閾値（指定した予測区間の外側なら異常とみなす）
P_THRESHOLD = 0.99
lower = (1 - P_THRESHOLD)/2  # 下限%
upper = 1 - lower  # 上限%

# パラメータごとのMCMCサンプルを保持
mcmc_Intercept <- mcmc_sample$Intercept
mcmc_beta <- mcmc_sample$beta
mcmc_sigma <- mcmc_sample$sigma

# 平均muと事後予測分布のMCMCサンプルを、データの説明変数ごとに作成
N_mcmc <- length(mcmc_sample$lp__)  # MCMCサンプルの個数
mcmc_mu <- as.data.frame(matrix(nrow=N_mcmc, ncol=N))  # muのMCMCサンプル格納用
mcmc_petal_width <- as.data.frame(matrix(nrow=N_mcmc, ncol=N))  # 予測分布MCMCサンプル格納用
# データごとにループ
for (i in 1:N){
  # 平均muのMCMCサンプル = 切片のMCMCサンプル + 係数のMCMCサンプル*Petal.Length
  mcmc_mu[,i] <- mcmc_Intercept + mcmc_beta*iris$Petal.Length[i]
  # 事後予測分布のMCMCサンプルを正規分布乱数から生成
  mcmc_petal_width[,i] <- rnorm(n=N_mcmc, mean=mcmc_mu[,i], sd=mcmc_sigma)
}

# 予測区間の上下限を取得
threshold <- apply(mcmc_petal_width,
                   2,
                   quantile,
                   probs=c(lower, upper))
rownames(threshold) <- c("lower", "upper")
# プロット用のDataFrame
df_outlier <- data.frame(
  df_iris,
  t(threshold)
)
# 予測区間の外側のデータ（異常値）を判定
df_outlier <- data.frame(
  df_outlier,
  outlier = df_outlier$petal_width < df_outlier$lower | df_outlier$petal_width > df_outlier$upper
)

# 予測区間と外れ値データをプロット
ggplot() +  
  theme_bw(base_size=18) +
  geom_ribbon(data=df_qua_petal_width,
              aes(x=petal_length, ymin=`0.5%`, ymax=`99.5%`),
              fill='black',
              alpha=1/6) +
  geom_ribbon(data=df_qua_petal_width,
              aes(x=petal_length, ymin=`2.5%`, ymax=`97.5%`),
              fill='black',
              alpha=2/6) +
  geom_line(data=df_qua_petal_width, aes(x=petal_length, y=`50%`), size=1) +
  geom_point(data=df_outlier, aes(x=petal_length, y=petal_width, color=outlier), size=2) +
  scale_colour_manual(values = c("blue", "red")) +
  labs(y='petal_width', title='Anomaly detection')
```
**・異常検知結果の可視化**
![00001b.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/610167/cadcb595-386f-e918-a959-97d8b2ff9883.png)
**赤い点**(outlier=TRUE)が**異常判定されたデータ**、青い点(outlier=FALSE)が正常判定されたデータを表しています。
また濃い灰色で塗り潰された部分が95%予測区間を、薄い灰色で塗りつぶされた部分が99%予測区間を表しています。
**99%予測区間の外側のデータが異常判定されている**事が、見てとれるかと思います。

実用上便利な使い方として、上記の「データごとにループ」の部分で使用しているデータに学習データ(MCMCに使用したデータ)とは異なるものを指定することで、未知データに対しても異常検知を実行できます。



## ユースケース10. ポアソン回帰モデル

応答変数：年間のノーヒットノーラン回数
説明変数：平均OPS、NPBかMLBか

https://1point02.jp/op/gnav/column/bs/column.aspx?cid=53067


# 評価指標の算出法

機械学習では[過学習と未学習のバランスを評価するためにクロスバリデーションがよく使用されますが](https://qiita.com/c60evaporator/items/ca7eb70e1508d2ba5359#学習データとテストデータ)、ベイズ統計モデリングではデータに対する適合度（尤度）とモデルのシンプルさ（変数や次数の少なさ）とのバランスを評価するために、AICやBIC、WAIC等の指標を使用します。

[こちらの書籍](https://www.kyoritsu-pub.co.jp/bookdetail/9784320112421)では指標に頼り切った判断は避けるべき（あくまでドメイン知識を主体としたモデル構築を推奨）と記載されていますが、使用法を学ぶ目的も兼ねて、後ほど算出法を紹介します。
